{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained resNet to predict species of plant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### descriptions\n",
    "1. **pandas** : reading csv file.(e.g., ground-truth)\n",
    "2. **torch** : load a model for prediction.\n",
    "3. **os** : find out your directory path.\n",
    "4. **cv2** : generate a numeric representation from your orginal image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the path your model stays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = 'ckpt'\n",
    "CKPT_PATH = os.path.join(CKPT_DIR, 'resNet_15_compose.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the ground-truth path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirpath</th>\n",
       "      <th>target</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DaanForestPark/20180330/1lZsRrQzj</td>\n",
       "      <td>通泉草</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DaanForestPark/20180330/4PdXwYcGt</td>\n",
       "      <td>紫花酢漿草</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DaanForestPark/20180330/6VrmeiUE5</td>\n",
       "      <td>通泉草</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DaanForestPark/20180330/7nrSoiuHL</td>\n",
       "      <td>通泉草</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DaanForestPark/20180330/7RKdkJLgy</td>\n",
       "      <td>通泉草</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             dirpath target  label\n",
       "0  DaanForestPark/20180330/1lZsRrQzj    通泉草     66\n",
       "1  DaanForestPark/20180330/4PdXwYcGt  紫花酢漿草     51\n",
       "2  DaanForestPark/20180330/6VrmeiUE5    通泉草     66\n",
       "3  DaanForestPark/20180330/7nrSoiuHL    通泉草     66\n",
       "4  DaanForestPark/20180330/7RKdkJLgy    通泉草     66"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL_DIR = 'label2.csv'\n",
    "label_df = pd.read_csv(LABEL_DIR)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define your img file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SAMPLE = 'sample/sample.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to RGB representaion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2rgb(path):\n",
    "    \"\"\"\n",
    "    :param path: String, location of the image file.\n",
    "    :returns rgb-format numpy array.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(path)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your .ckpt model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the result when an image comes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of oneshot=torch.Size([1, 3, 192, 340])\n",
      "shape of pred=torch.Size([1, 85])\n"
     ]
    }
   ],
   "source": [
    "# convert image to rgb-format numpy array\n",
    "oneshot = img2rgb(DATA_SAMPLE)\n",
    "# do dimension transpose: (height, weidth, channel) to (channel, height, weidth)\n",
    "oneshot = torch.Tensor(oneshot).permute(2,0,1).unsqueeze(0)\n",
    "# use the cuda wrapper\n",
    "oneshot = oneshot.cuda()\n",
    "# input shape\n",
    "print('shape of oneshot={}'.format(oneshot.shape))\n",
    "pred = model(oneshot)\n",
    "# output shape\n",
    "print('shape of pred={}'.format(pred.shape))\n",
    "# get a predicted label\n",
    "_, predicted = torch.max(pred.cpu().data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted result is 通泉草\n"
     ]
    }
   ],
   "source": [
    "res = label_df[label_df['label']==predicted.item()]['target'].unique()[0]\n",
    "print('the predicted result is {}'.format(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input.1 : Float(1, 3, 224, 224),\n",
      "      %conv1.weight : Float(64, 3, 7, 7),\n",
      "      %bn1.weight : Float(64),\n",
      "      %bn1.bias : Float(64),\n",
      "      %bn1.running_mean : Float(64),\n",
      "      %bn1.running_var : Float(64),\n",
      "      %bn1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.bn1.weight : Float(64),\n",
      "      %layer1.0.bn1.bias : Float(64),\n",
      "      %layer1.0.bn1.running_mean : Float(64),\n",
      "      %layer1.0.bn1.running_var : Float(64),\n",
      "      %layer1.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer1.0.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.0.bn2.weight : Float(64),\n",
      "      %layer1.0.bn2.bias : Float(64),\n",
      "      %layer1.0.bn2.running_mean : Float(64),\n",
      "      %layer1.0.bn2.running_var : Float(64),\n",
      "      %layer1.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv1.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.bn1.weight : Float(64),\n",
      "      %layer1.1.bn1.bias : Float(64),\n",
      "      %layer1.1.bn1.running_mean : Float(64),\n",
      "      %layer1.1.bn1.running_var : Float(64),\n",
      "      %layer1.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer1.1.conv2.weight : Float(64, 64, 3, 3),\n",
      "      %layer1.1.bn2.weight : Float(64),\n",
      "      %layer1.1.bn2.bias : Float(64),\n",
      "      %layer1.1.bn2.running_mean : Float(64),\n",
      "      %layer1.1.bn2.running_var : Float(64),\n",
      "      %layer1.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv1.weight : Float(128, 64, 3, 3),\n",
      "      %layer2.0.bn1.weight : Float(128),\n",
      "      %layer2.0.bn1.bias : Float(128),\n",
      "      %layer2.0.bn1.running_mean : Float(128),\n",
      "      %layer2.0.bn1.running_var : Float(128),\n",
      "      %layer2.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer2.0.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.0.bn2.weight : Float(128),\n",
      "      %layer2.0.bn2.bias : Float(128),\n",
      "      %layer2.0.bn2.running_mean : Float(128),\n",
      "      %layer2.0.bn2.running_var : Float(128),\n",
      "      %layer2.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer2.0.downsample.0.weight : Float(128, 64, 1, 1),\n",
      "      %layer2.0.downsample.1.weight : Float(128),\n",
      "      %layer2.0.downsample.1.bias : Float(128),\n",
      "      %layer2.0.downsample.1.running_mean : Float(128),\n",
      "      %layer2.0.downsample.1.running_var : Float(128),\n",
      "      %layer2.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv1.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.bn1.weight : Float(128),\n",
      "      %layer2.1.bn1.bias : Float(128),\n",
      "      %layer2.1.bn1.running_mean : Float(128),\n",
      "      %layer2.1.bn1.running_var : Float(128),\n",
      "      %layer2.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer2.1.conv2.weight : Float(128, 128, 3, 3),\n",
      "      %layer2.1.bn2.weight : Float(128),\n",
      "      %layer2.1.bn2.bias : Float(128),\n",
      "      %layer2.1.bn2.running_mean : Float(128),\n",
      "      %layer2.1.bn2.running_var : Float(128),\n",
      "      %layer2.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv1.weight : Float(256, 128, 3, 3),\n",
      "      %layer3.0.bn1.weight : Float(256),\n",
      "      %layer3.0.bn1.bias : Float(256),\n",
      "      %layer3.0.bn1.running_mean : Float(256),\n",
      "      %layer3.0.bn1.running_var : Float(256),\n",
      "      %layer3.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer3.0.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.0.bn2.weight : Float(256),\n",
      "      %layer3.0.bn2.bias : Float(256),\n",
      "      %layer3.0.bn2.running_mean : Float(256),\n",
      "      %layer3.0.bn2.running_var : Float(256),\n",
      "      %layer3.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer3.0.downsample.0.weight : Float(256, 128, 1, 1),\n",
      "      %layer3.0.downsample.1.weight : Float(256),\n",
      "      %layer3.0.downsample.1.bias : Float(256),\n",
      "      %layer3.0.downsample.1.running_mean : Float(256),\n",
      "      %layer3.0.downsample.1.running_var : Float(256),\n",
      "      %layer3.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv1.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.bn1.weight : Float(256),\n",
      "      %layer3.1.bn1.bias : Float(256),\n",
      "      %layer3.1.bn1.running_mean : Float(256),\n",
      "      %layer3.1.bn1.running_var : Float(256),\n",
      "      %layer3.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer3.1.conv2.weight : Float(256, 256, 3, 3),\n",
      "      %layer3.1.bn2.weight : Float(256),\n",
      "      %layer3.1.bn2.bias : Float(256),\n",
      "      %layer3.1.bn2.running_mean : Float(256),\n",
      "      %layer3.1.bn2.running_var : Float(256),\n",
      "      %layer3.1.bn2.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv1.weight : Float(512, 256, 3, 3),\n",
      "      %layer4.0.bn1.weight : Float(512),\n",
      "      %layer4.0.bn1.bias : Float(512),\n",
      "      %layer4.0.bn1.running_mean : Float(512),\n",
      "      %layer4.0.bn1.running_var : Float(512),\n",
      "      %layer4.0.bn1.num_batches_tracked : Long(),\n",
      "      %layer4.0.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.0.bn2.weight : Float(512),\n",
      "      %layer4.0.bn2.bias : Float(512),\n",
      "      %layer4.0.bn2.running_mean : Float(512),\n",
      "      %layer4.0.bn2.running_var : Float(512),\n",
      "      %layer4.0.bn2.num_batches_tracked : Long(),\n",
      "      %layer4.0.downsample.0.weight : Float(512, 256, 1, 1),\n",
      "      %layer4.0.downsample.1.weight : Float(512),\n",
      "      %layer4.0.downsample.1.bias : Float(512),\n",
      "      %layer4.0.downsample.1.running_mean : Float(512),\n",
      "      %layer4.0.downsample.1.running_var : Float(512),\n",
      "      %layer4.0.downsample.1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv1.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.bn1.weight : Float(512),\n",
      "      %layer4.1.bn1.bias : Float(512),\n",
      "      %layer4.1.bn1.running_mean : Float(512),\n",
      "      %layer4.1.bn1.running_var : Float(512),\n",
      "      %layer4.1.bn1.num_batches_tracked : Long(),\n",
      "      %layer4.1.conv2.weight : Float(512, 512, 3, 3),\n",
      "      %layer4.1.bn2.weight : Float(512),\n",
      "      %layer4.1.bn2.bias : Float(512),\n",
      "      %layer4.1.bn2.running_mean : Float(512),\n",
      "      %layer4.1.bn2.running_var : Float(512),\n",
      "      %layer4.1.bn2.num_batches_tracked : Long(),\n",
      "      %fc.weight : Float(85, 512),\n",
      "      %fc.bias : Float(85)):\n",
      "  %123 : Float(1, 64, 112, 112) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%input.1, %conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %124 : Float(1, 64, 112, 112) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%123, %bn1.weight, %bn1.bias, %bn1.running_mean, %bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %125 : Float(1, 64, 112, 112) = onnx::Relu(%124) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %126 : Float(1, 64, 56, 56) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:488:0\n",
      "  %127 : Float(1, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %layer1.0.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %128 : Float(1, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%127, %layer1.0.bn1.weight, %layer1.0.bn1.bias, %layer1.0.bn1.running_mean, %layer1.0.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %129 : Float(1, 64, 56, 56) = onnx::Relu(%128) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %130 : Float(1, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %layer1.0.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %131 : Float(1, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%130, %layer1.0.bn2.weight, %layer1.0.bn2.bias, %layer1.0.bn2.running_mean, %layer1.0.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %132 : Float(1, 64, 56, 56) = onnx::Add(%131, %126) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %133 : Float(1, 64, 56, 56) = onnx::Relu(%132) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %134 : Float(1, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %layer1.1.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %135 : Float(1, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%134, %layer1.1.bn1.weight, %layer1.1.bn1.bias, %layer1.1.bn1.running_mean, %layer1.1.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %136 : Float(1, 64, 56, 56) = onnx::Relu(%135) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %137 : Float(1, 64, 56, 56) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %layer1.1.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %138 : Float(1, 64, 56, 56) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%137, %layer1.1.bn2.weight, %layer1.1.bn2.bias, %layer1.1.bn2.running_mean, %layer1.1.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %139 : Float(1, 64, 56, 56) = onnx::Add(%138, %133) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %140 : Float(1, 64, 56, 56) = onnx::Relu(%139) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %141 : Float(1, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %layer2.0.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %142 : Float(1, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%141, %layer2.0.bn1.weight, %layer2.0.bn1.bias, %layer2.0.bn1.running_mean, %layer2.0.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %143 : Float(1, 128, 28, 28) = onnx::Relu(%142) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %144 : Float(1, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %layer2.0.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %145 : Float(1, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%144, %layer2.0.bn2.weight, %layer2.0.bn2.bias, %layer2.0.bn2.running_mean, %layer2.0.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %146 : Float(1, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %layer2.0.downsample.0.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %147 : Float(1, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%146, %layer2.0.downsample.1.weight, %layer2.0.downsample.1.bias, %layer2.0.downsample.1.running_mean, %layer2.0.downsample.1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %148 : Float(1, 128, 28, 28) = onnx::Add(%145, %147) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %149 : Float(1, 128, 28, 28) = onnx::Relu(%148) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %150 : Float(1, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %layer2.1.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %151 : Float(1, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%150, %layer2.1.bn1.weight, %layer2.1.bn1.bias, %layer2.1.bn1.running_mean, %layer2.1.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %152 : Float(1, 128, 28, 28) = onnx::Relu(%151) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %153 : Float(1, 128, 28, 28) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %layer2.1.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %154 : Float(1, 128, 28, 28) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%153, %layer2.1.bn2.weight, %layer2.1.bn2.bias, %layer2.1.bn2.running_mean, %layer2.1.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %155 : Float(1, 128, 28, 28) = onnx::Add(%154, %149) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %156 : Float(1, 128, 28, 28) = onnx::Relu(%155) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %157 : Float(1, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %layer3.0.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %158 : Float(1, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%157, %layer3.0.bn1.weight, %layer3.0.bn1.bias, %layer3.0.bn1.running_mean, %layer3.0.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %159 : Float(1, 256, 14, 14) = onnx::Relu(%158) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %160 : Float(1, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %layer3.0.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %161 : Float(1, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%160, %layer3.0.bn2.weight, %layer3.0.bn2.bias, %layer3.0.bn2.running_mean, %layer3.0.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %162 : Float(1, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %layer3.0.downsample.0.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %163 : Float(1, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%162, %layer3.0.downsample.1.weight, %layer3.0.downsample.1.bias, %layer3.0.downsample.1.running_mean, %layer3.0.downsample.1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %164 : Float(1, 256, 14, 14) = onnx::Add(%161, %163) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %165 : Float(1, 256, 14, 14) = onnx::Relu(%164) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %166 : Float(1, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %layer3.1.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %167 : Float(1, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%166, %layer3.1.bn1.weight, %layer3.1.bn1.bias, %layer3.1.bn1.running_mean, %layer3.1.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %168 : Float(1, 256, 14, 14) = onnx::Relu(%167) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %169 : Float(1, 256, 14, 14) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %layer3.1.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %170 : Float(1, 256, 14, 14) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%169, %layer3.1.bn2.weight, %layer3.1.bn2.bias, %layer3.1.bn2.running_mean, %layer3.1.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %171 : Float(1, 256, 14, 14) = onnx::Add(%170, %165) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %172 : Float(1, 256, 14, 14) = onnx::Relu(%171) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %173 : Float(1, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %layer4.0.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %174 : Float(1, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%173, %layer4.0.bn1.weight, %layer4.0.bn1.bias, %layer4.0.bn1.running_mean, %layer4.0.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %175 : Float(1, 512, 7, 7) = onnx::Relu(%174) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %176 : Float(1, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %layer4.0.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %177 : Float(1, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%176, %layer4.0.bn2.weight, %layer4.0.bn2.bias, %layer4.0.bn2.running_mean, %layer4.0.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %178 : Float(1, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %layer4.0.downsample.0.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %179 : Float(1, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%178, %layer4.0.downsample.1.weight, %layer4.0.downsample.1.bias, %layer4.0.downsample.1.running_mean, %layer4.0.downsample.1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %180 : Float(1, 512, 7, 7) = onnx::Add(%177, %179) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %181 : Float(1, 512, 7, 7) = onnx::Relu(%180) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %182 : Float(1, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %layer4.1.conv1.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %183 : Float(1, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%182, %layer4.1.bn1.weight, %layer4.1.bn1.bias, %layer4.1.bn1.running_mean, %layer4.1.bn1.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %184 : Float(1, 512, 7, 7) = onnx::Relu(%183) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %185 : Float(1, 512, 7, 7) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %layer4.1.conv2.weight) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/modules/conv.py:342:0\n",
      "  %186 : Float(1, 512, 7, 7) = onnx::BatchNormalization[epsilon=1e-05, momentum=0.9](%185, %layer4.1.bn2.weight, %layer4.1.bn2.bias, %layer4.1.bn2.running_mean, %layer4.1.bn2.running_var) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1670:0\n",
      "  %187 : Float(1, 512, 7, 7) = onnx::Add(%186, %181) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:70:0\n",
      "  %188 : Float(1, 512, 7, 7) = onnx::Relu(%187) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:912:0\n",
      "  %189 : Float(1, 512, 1, 1) = onnx::GlobalAveragePool(%188) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:768:0\n",
      "  %190 : Float(1, 512) = onnx::Flatten[axis=1](%189) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torchvision/models/resnet.py:210:0\n",
      "  %191 : Float(1, 85) = onnx::Gemm[alpha=1, beta=1, transB=1](%190, %fc.weight, %fc.bias) # /home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/torch/nn/functional.py:1370:0\n",
      "  return (%191)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_names = ['whole_model.ckpt']\n",
    "model = torch.load(input_names[0]) # map_location='cpu'\n",
    "feature = torch.rand(1, 3, 224, 224).cuda()\n",
    "for key, module in model._modules.items():\n",
    "    input_names.append(\"l_{}_\".format(key) + module._get_name())\n",
    "torch_out = torch.onnx.export(model,feature,\"model_best.onnx\", export_params = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/69: Converting Node Type Conv\n",
      "2/69: Converting Node Type BatchNormalization\n",
      "3/69: Converting Node Type Relu\n",
      "4/69: Converting Node Type MaxPool\n",
      "5/69: Converting Node Type Conv\n",
      "6/69: Converting Node Type BatchNormalization\n",
      "7/69: Converting Node Type Relu\n",
      "8/69: Converting Node Type Conv\n",
      "9/69: Converting Node Type BatchNormalization\n",
      "10/69: Converting Node Type Add\n",
      "11/69: Converting Node Type Relu\n",
      "12/69: Converting Node Type Conv\n",
      "13/69: Converting Node Type BatchNormalization\n",
      "14/69: Converting Node Type Relu\n",
      "15/69: Converting Node Type Conv\n",
      "16/69: Converting Node Type BatchNormalization\n",
      "17/69: Converting Node Type Add\n",
      "18/69: Converting Node Type Relu\n",
      "19/69: Converting Node Type Conv\n",
      "20/69: Converting Node Type BatchNormalization\n",
      "21/69: Converting Node Type Relu\n",
      "22/69: Converting Node Type Conv\n",
      "23/69: Converting Node Type BatchNormalization\n",
      "24/69: Converting Node Type Conv\n",
      "25/69: Converting Node Type BatchNormalization\n",
      "26/69: Converting Node Type Add\n",
      "27/69: Converting Node Type Relu\n",
      "28/69: Converting Node Type Conv\n",
      "29/69: Converting Node Type BatchNormalization\n",
      "30/69: Converting Node Type Relu\n",
      "31/69: Converting Node Type Conv\n",
      "32/69: Converting Node Type BatchNormalization\n",
      "33/69: Converting Node Type Add\n",
      "34/69: Converting Node Type Relu\n",
      "35/69: Converting Node Type Conv\n",
      "36/69: Converting Node Type BatchNormalization\n",
      "37/69: Converting Node Type Relu\n",
      "38/69: Converting Node Type Conv\n",
      "39/69: Converting Node Type BatchNormalization\n",
      "40/69: Converting Node Type Conv\n",
      "41/69: Converting Node Type BatchNormalization\n",
      "42/69: Converting Node Type Add\n",
      "43/69: Converting Node Type Relu\n",
      "44/69: Converting Node Type Conv\n",
      "45/69: Converting Node Type BatchNormalization\n",
      "46/69: Converting Node Type Relu\n",
      "47/69: Converting Node Type Conv\n",
      "48/69: Converting Node Type BatchNormalization\n",
      "49/69: Converting Node Type Add\n",
      "50/69: Converting Node Type Relu\n",
      "51/69: Converting Node Type Conv\n",
      "52/69: Converting Node Type BatchNormalization\n",
      "53/69: Converting Node Type Relu\n",
      "54/69: Converting Node Type Conv\n",
      "55/69: Converting Node Type BatchNormalization\n",
      "56/69: Converting Node Type Conv\n",
      "57/69: Converting Node Type BatchNormalization\n",
      "58/69: Converting Node Type Add\n",
      "59/69: Converting Node Type Relu\n",
      "60/69: Converting Node Type Conv\n",
      "61/69: Converting Node Type BatchNormalization\n",
      "62/69: Converting Node Type Relu\n",
      "63/69: Converting Node Type Conv\n",
      "64/69: Converting Node Type BatchNormalization\n",
      "65/69: Converting Node Type Add\n",
      "66/69: Converting Node Type Relu\n",
      "67/69: Converting Node Type GlobalAveragePool\n",
      "68/69: Converting Node Type Flatten\n",
      "69/69: Converting Node Type Gemm\n",
      "Translation to CoreML spec completed. Now compiling the CoreML model.\n",
      "Model Compilation done.\n"
     ]
    }
   ],
   "source": [
    "from onnx_coreml import convert\n",
    "# Load the ONNX model as a CoreML model\n",
    "model = convert(model='model_best.onnx',minimum_ios_deployment_target='13')\n",
    "# Save the CoreML model\n",
    "model.save('model_best.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7481320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7481320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7481320>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7481320>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7479ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7479ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7479ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f9cd7479ba8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "Outputs(_0=array([[-30.580627  , -18.302422  , -15.592232  ,  -8.550749  ,\n",
      "          4.536593  , -16.788334  , -23.898138  , -18.951075  ,\n",
      "         -4.141205  , -36.41709   , -13.530774  , -21.265617  ,\n",
      "        -10.161818  ,  -4.075833  , -18.544773  , -11.917788  ,\n",
      "         -9.666152  , -10.244947  , -18.063549  , -10.536639  ,\n",
      "        -54.119957  , -15.330414  , -30.279728  , -28.075468  ,\n",
      "        -11.328012  , -14.885237  , -11.608006  , -18.634571  ,\n",
      "          2.6173368 , -18.80939   ,  -5.860074  ,  -4.4285226 ,\n",
      "         -2.3426192 , -13.649957  ,  -1.5870097 , -12.193731  ,\n",
      "         -3.089502  ,  -7.6164265 , -46.43792   ,  -0.22160596,\n",
      "        -12.99589   , -33.641834  , -22.098078  , -13.390219  ,\n",
      "         -4.4619775 , -14.958099  ,  -0.1549378 , -12.013525  ,\n",
      "        -23.318712  ,  -6.485461  ,  -4.540246  , -13.017415  ,\n",
      "        -38.343224  ,  -9.459365  , -18.22016   ,  -3.8872442 ,\n",
      "          1.4387465 , -29.506432  , -14.600282  , -13.111201  ,\n",
      "         -9.987908  ,  -5.6605663 , -30.467554  , -24.408436  ,\n",
      "        -13.033996  ,  -8.515506  , -20.147875  ,   0.07643563,\n",
      "        -17.064594  , -12.636768  , -14.489106  , -16.959225  ,\n",
      "        -11.237813  , -16.311588  , -21.0834    ,  -7.9295063 ,\n",
      "         -7.6702223 , -30.64472   ,  -2.0525453 , -15.125823  ,\n",
      "         -9.417855  , -21.342058  ,  -8.460524  , -17.84778   ,\n",
      "        -13.509184  ]], dtype=float32))\n",
      "['input.1']\n",
      "-----\n",
      "['191']\n",
      "-----\n",
      "{'bn1.bias': <tf.Tensor 'Const:0' shape=(64,) dtype=float32>, 'bn1.num_batches_tracked': <tf.Tensor 'Const_1:0' shape=() dtype=int64>, 'bn1.running_mean': <tf.Tensor 'Const_2:0' shape=(64,) dtype=float32>, 'bn1.running_var': <tf.Tensor 'Const_3:0' shape=(64,) dtype=float32>, 'bn1.weight': <tf.Tensor 'Const_4:0' shape=(64,) dtype=float32>, 'conv1.weight': <tf.Tensor 'Const_5:0' shape=(64, 3, 7, 7) dtype=float32>, 'fc.bias': <tf.Tensor 'Const_6:0' shape=(85,) dtype=float32>, 'fc.weight': <tf.Tensor 'Const_7:0' shape=(85, 512) dtype=float32>, 'layer1.0.bn1.bias': <tf.Tensor 'Const_8:0' shape=(64,) dtype=float32>, 'layer1.0.bn1.num_batches_tracked': <tf.Tensor 'Const_9:0' shape=() dtype=int64>, 'layer1.0.bn1.running_mean': <tf.Tensor 'Const_10:0' shape=(64,) dtype=float32>, 'layer1.0.bn1.running_var': <tf.Tensor 'Const_11:0' shape=(64,) dtype=float32>, 'layer1.0.bn1.weight': <tf.Tensor 'Const_12:0' shape=(64,) dtype=float32>, 'layer1.0.bn2.bias': <tf.Tensor 'Const_13:0' shape=(64,) dtype=float32>, 'layer1.0.bn2.num_batches_tracked': <tf.Tensor 'Const_14:0' shape=() dtype=int64>, 'layer1.0.bn2.running_mean': <tf.Tensor 'Const_15:0' shape=(64,) dtype=float32>, 'layer1.0.bn2.running_var': <tf.Tensor 'Const_16:0' shape=(64,) dtype=float32>, 'layer1.0.bn2.weight': <tf.Tensor 'Const_17:0' shape=(64,) dtype=float32>, 'layer1.0.conv1.weight': <tf.Tensor 'Const_18:0' shape=(64, 64, 3, 3) dtype=float32>, 'layer1.0.conv2.weight': <tf.Tensor 'Const_19:0' shape=(64, 64, 3, 3) dtype=float32>, 'layer1.1.bn1.bias': <tf.Tensor 'Const_20:0' shape=(64,) dtype=float32>, 'layer1.1.bn1.num_batches_tracked': <tf.Tensor 'Const_21:0' shape=() dtype=int64>, 'layer1.1.bn1.running_mean': <tf.Tensor 'Const_22:0' shape=(64,) dtype=float32>, 'layer1.1.bn1.running_var': <tf.Tensor 'Const_23:0' shape=(64,) dtype=float32>, 'layer1.1.bn1.weight': <tf.Tensor 'Const_24:0' shape=(64,) dtype=float32>, 'layer1.1.bn2.bias': <tf.Tensor 'Const_25:0' shape=(64,) dtype=float32>, 'layer1.1.bn2.num_batches_tracked': <tf.Tensor 'Const_26:0' shape=() dtype=int64>, 'layer1.1.bn2.running_mean': <tf.Tensor 'Const_27:0' shape=(64,) dtype=float32>, 'layer1.1.bn2.running_var': <tf.Tensor 'Const_28:0' shape=(64,) dtype=float32>, 'layer1.1.bn2.weight': <tf.Tensor 'Const_29:0' shape=(64,) dtype=float32>, 'layer1.1.conv1.weight': <tf.Tensor 'Const_30:0' shape=(64, 64, 3, 3) dtype=float32>, 'layer1.1.conv2.weight': <tf.Tensor 'Const_31:0' shape=(64, 64, 3, 3) dtype=float32>, 'layer2.0.bn1.bias': <tf.Tensor 'Const_32:0' shape=(128,) dtype=float32>, 'layer2.0.bn1.num_batches_tracked': <tf.Tensor 'Const_33:0' shape=() dtype=int64>, 'layer2.0.bn1.running_mean': <tf.Tensor 'Const_34:0' shape=(128,) dtype=float32>, 'layer2.0.bn1.running_var': <tf.Tensor 'Const_35:0' shape=(128,) dtype=float32>, 'layer2.0.bn1.weight': <tf.Tensor 'Const_36:0' shape=(128,) dtype=float32>, 'layer2.0.bn2.bias': <tf.Tensor 'Const_37:0' shape=(128,) dtype=float32>, 'layer2.0.bn2.num_batches_tracked': <tf.Tensor 'Const_38:0' shape=() dtype=int64>, 'layer2.0.bn2.running_mean': <tf.Tensor 'Const_39:0' shape=(128,) dtype=float32>, 'layer2.0.bn2.running_var': <tf.Tensor 'Const_40:0' shape=(128,) dtype=float32>, 'layer2.0.bn2.weight': <tf.Tensor 'Const_41:0' shape=(128,) dtype=float32>, 'layer2.0.conv1.weight': <tf.Tensor 'Const_42:0' shape=(128, 64, 3, 3) dtype=float32>, 'layer2.0.conv2.weight': <tf.Tensor 'Const_43:0' shape=(128, 128, 3, 3) dtype=float32>, 'layer2.0.downsample.0.weight': <tf.Tensor 'Const_44:0' shape=(128, 64, 1, 1) dtype=float32>, 'layer2.0.downsample.1.bias': <tf.Tensor 'Const_45:0' shape=(128,) dtype=float32>, 'layer2.0.downsample.1.num_batches_tracked': <tf.Tensor 'Const_46:0' shape=() dtype=int64>, 'layer2.0.downsample.1.running_mean': <tf.Tensor 'Const_47:0' shape=(128,) dtype=float32>, 'layer2.0.downsample.1.running_var': <tf.Tensor 'Const_48:0' shape=(128,) dtype=float32>, 'layer2.0.downsample.1.weight': <tf.Tensor 'Const_49:0' shape=(128,) dtype=float32>, 'layer2.1.bn1.bias': <tf.Tensor 'Const_50:0' shape=(128,) dtype=float32>, 'layer2.1.bn1.num_batches_tracked': <tf.Tensor 'Const_51:0' shape=() dtype=int64>, 'layer2.1.bn1.running_mean': <tf.Tensor 'Const_52:0' shape=(128,) dtype=float32>, 'layer2.1.bn1.running_var': <tf.Tensor 'Const_53:0' shape=(128,) dtype=float32>, 'layer2.1.bn1.weight': <tf.Tensor 'Const_54:0' shape=(128,) dtype=float32>, 'layer2.1.bn2.bias': <tf.Tensor 'Const_55:0' shape=(128,) dtype=float32>, 'layer2.1.bn2.num_batches_tracked': <tf.Tensor 'Const_56:0' shape=() dtype=int64>, 'layer2.1.bn2.running_mean': <tf.Tensor 'Const_57:0' shape=(128,) dtype=float32>, 'layer2.1.bn2.running_var': <tf.Tensor 'Const_58:0' shape=(128,) dtype=float32>, 'layer2.1.bn2.weight': <tf.Tensor 'Const_59:0' shape=(128,) dtype=float32>, 'layer2.1.conv1.weight': <tf.Tensor 'Const_60:0' shape=(128, 128, 3, 3) dtype=float32>, 'layer2.1.conv2.weight': <tf.Tensor 'Const_61:0' shape=(128, 128, 3, 3) dtype=float32>, 'layer3.0.bn1.bias': <tf.Tensor 'Const_62:0' shape=(256,) dtype=float32>, 'layer3.0.bn1.num_batches_tracked': <tf.Tensor 'Const_63:0' shape=() dtype=int64>, 'layer3.0.bn1.running_mean': <tf.Tensor 'Const_64:0' shape=(256,) dtype=float32>, 'layer3.0.bn1.running_var': <tf.Tensor 'Const_65:0' shape=(256,) dtype=float32>, 'layer3.0.bn1.weight': <tf.Tensor 'Const_66:0' shape=(256,) dtype=float32>, 'layer3.0.bn2.bias': <tf.Tensor 'Const_67:0' shape=(256,) dtype=float32>, 'layer3.0.bn2.num_batches_tracked': <tf.Tensor 'Const_68:0' shape=() dtype=int64>, 'layer3.0.bn2.running_mean': <tf.Tensor 'Const_69:0' shape=(256,) dtype=float32>, 'layer3.0.bn2.running_var': <tf.Tensor 'Const_70:0' shape=(256,) dtype=float32>, 'layer3.0.bn2.weight': <tf.Tensor 'Const_71:0' shape=(256,) dtype=float32>, 'layer3.0.conv1.weight': <tf.Tensor 'Const_72:0' shape=(256, 128, 3, 3) dtype=float32>, 'layer3.0.conv2.weight': <tf.Tensor 'Const_73:0' shape=(256, 256, 3, 3) dtype=float32>, 'layer3.0.downsample.0.weight': <tf.Tensor 'Const_74:0' shape=(256, 128, 1, 1) dtype=float32>, 'layer3.0.downsample.1.bias': <tf.Tensor 'Const_75:0' shape=(256,) dtype=float32>, 'layer3.0.downsample.1.num_batches_tracked': <tf.Tensor 'Const_76:0' shape=() dtype=int64>, 'layer3.0.downsample.1.running_mean': <tf.Tensor 'Const_77:0' shape=(256,) dtype=float32>, 'layer3.0.downsample.1.running_var': <tf.Tensor 'Const_78:0' shape=(256,) dtype=float32>, 'layer3.0.downsample.1.weight': <tf.Tensor 'Const_79:0' shape=(256,) dtype=float32>, 'layer3.1.bn1.bias': <tf.Tensor 'Const_80:0' shape=(256,) dtype=float32>, 'layer3.1.bn1.num_batches_tracked': <tf.Tensor 'Const_81:0' shape=() dtype=int64>, 'layer3.1.bn1.running_mean': <tf.Tensor 'Const_82:0' shape=(256,) dtype=float32>, 'layer3.1.bn1.running_var': <tf.Tensor 'Const_83:0' shape=(256,) dtype=float32>, 'layer3.1.bn1.weight': <tf.Tensor 'Const_84:0' shape=(256,) dtype=float32>, 'layer3.1.bn2.bias': <tf.Tensor 'Const_85:0' shape=(256,) dtype=float32>, 'layer3.1.bn2.num_batches_tracked': <tf.Tensor 'Const_86:0' shape=() dtype=int64>, 'layer3.1.bn2.running_mean': <tf.Tensor 'Const_87:0' shape=(256,) dtype=float32>, 'layer3.1.bn2.running_var': <tf.Tensor 'Const_88:0' shape=(256,) dtype=float32>, 'layer3.1.bn2.weight': <tf.Tensor 'Const_89:0' shape=(256,) dtype=float32>, 'layer3.1.conv1.weight': <tf.Tensor 'Const_90:0' shape=(256, 256, 3, 3) dtype=float32>, 'layer3.1.conv2.weight': <tf.Tensor 'Const_91:0' shape=(256, 256, 3, 3) dtype=float32>, 'layer4.0.bn1.bias': <tf.Tensor 'Const_92:0' shape=(512,) dtype=float32>, 'layer4.0.bn1.num_batches_tracked': <tf.Tensor 'Const_93:0' shape=() dtype=int64>, 'layer4.0.bn1.running_mean': <tf.Tensor 'Const_94:0' shape=(512,) dtype=float32>, 'layer4.0.bn1.running_var': <tf.Tensor 'Const_95:0' shape=(512,) dtype=float32>, 'layer4.0.bn1.weight': <tf.Tensor 'Const_96:0' shape=(512,) dtype=float32>, 'layer4.0.bn2.bias': <tf.Tensor 'Const_97:0' shape=(512,) dtype=float32>, 'layer4.0.bn2.num_batches_tracked': <tf.Tensor 'Const_98:0' shape=() dtype=int64>, 'layer4.0.bn2.running_mean': <tf.Tensor 'Const_99:0' shape=(512,) dtype=float32>, 'layer4.0.bn2.running_var': <tf.Tensor 'Const_100:0' shape=(512,) dtype=float32>, 'layer4.0.bn2.weight': <tf.Tensor 'Const_101:0' shape=(512,) dtype=float32>, 'layer4.0.conv1.weight': <tf.Tensor 'Const_102:0' shape=(512, 256, 3, 3) dtype=float32>, 'layer4.0.conv2.weight': <tf.Tensor 'Const_103:0' shape=(512, 512, 3, 3) dtype=float32>, 'layer4.0.downsample.0.weight': <tf.Tensor 'Const_104:0' shape=(512, 256, 1, 1) dtype=float32>, 'layer4.0.downsample.1.bias': <tf.Tensor 'Const_105:0' shape=(512,) dtype=float32>, 'layer4.0.downsample.1.num_batches_tracked': <tf.Tensor 'Const_106:0' shape=() dtype=int64>, 'layer4.0.downsample.1.running_mean': <tf.Tensor 'Const_107:0' shape=(512,) dtype=float32>, 'layer4.0.downsample.1.running_var': <tf.Tensor 'Const_108:0' shape=(512,) dtype=float32>, 'layer4.0.downsample.1.weight': <tf.Tensor 'Const_109:0' shape=(512,) dtype=float32>, 'layer4.1.bn1.bias': <tf.Tensor 'Const_110:0' shape=(512,) dtype=float32>, 'layer4.1.bn1.num_batches_tracked': <tf.Tensor 'Const_111:0' shape=() dtype=int64>, 'layer4.1.bn1.running_mean': <tf.Tensor 'Const_112:0' shape=(512,) dtype=float32>, 'layer4.1.bn1.running_var': <tf.Tensor 'Const_113:0' shape=(512,) dtype=float32>, 'layer4.1.bn1.weight': <tf.Tensor 'Const_114:0' shape=(512,) dtype=float32>, 'layer4.1.bn2.bias': <tf.Tensor 'Const_115:0' shape=(512,) dtype=float32>, 'layer4.1.bn2.num_batches_tracked': <tf.Tensor 'Const_116:0' shape=() dtype=int64>, 'layer4.1.bn2.running_mean': <tf.Tensor 'Const_117:0' shape=(512,) dtype=float32>, 'layer4.1.bn2.running_var': <tf.Tensor 'Const_118:0' shape=(512,) dtype=float32>, 'layer4.1.bn2.weight': <tf.Tensor 'Const_119:0' shape=(512,) dtype=float32>, 'layer4.1.conv1.weight': <tf.Tensor 'Const_120:0' shape=(512, 512, 3, 3) dtype=float32>, 'layer4.1.conv2.weight': <tf.Tensor 'Const_121:0' shape=(512, 512, 3, 3) dtype=float32>, 'input.1': <tf.Tensor 'input.1:0' shape=(1, 3, 224, 224) dtype=float32>, '123': <tf.Tensor 'transpose_2:0' shape=(1, 64, 112, 112) dtype=float32>, '124': <tf.Tensor 'batchnorm/add_1:0' shape=(1, 64, 112, 112) dtype=float32>, '125': <tf.Tensor 'Relu:0' shape=(1, 64, 112, 112) dtype=float32>, '126': <tf.Tensor 'PyFunc:0' shape=(1, 64, 56, 56) dtype=float32>, '127': <tf.Tensor 'transpose_5:0' shape=(1, 64, 56, 56) dtype=float32>, '128': <tf.Tensor 'batchnorm_1/add_1:0' shape=(1, 64, 56, 56) dtype=float32>, '129': <tf.Tensor 'Relu_1:0' shape=(1, 64, 56, 56) dtype=float32>, '130': <tf.Tensor 'transpose_8:0' shape=(1, 64, 56, 56) dtype=float32>, '131': <tf.Tensor 'batchnorm_2/add_1:0' shape=(1, 64, 56, 56) dtype=float32>, '132': <tf.Tensor 'Add:0' shape=(1, 64, 56, 56) dtype=float32>, '133': <tf.Tensor 'Relu_2:0' shape=(1, 64, 56, 56) dtype=float32>, '134': <tf.Tensor 'transpose_11:0' shape=(1, 64, 56, 56) dtype=float32>, '135': <tf.Tensor 'batchnorm_3/add_1:0' shape=(1, 64, 56, 56) dtype=float32>, '136': <tf.Tensor 'Relu_3:0' shape=(1, 64, 56, 56) dtype=float32>, '137': <tf.Tensor 'transpose_14:0' shape=(1, 64, 56, 56) dtype=float32>, '138': <tf.Tensor 'batchnorm_4/add_1:0' shape=(1, 64, 56, 56) dtype=float32>, '139': <tf.Tensor 'Add_1:0' shape=(1, 64, 56, 56) dtype=float32>, '140': <tf.Tensor 'Relu_4:0' shape=(1, 64, 56, 56) dtype=float32>, '141': <tf.Tensor 'transpose_17:0' shape=(1, 128, 28, 28) dtype=float32>, '142': <tf.Tensor 'batchnorm_5/add_1:0' shape=(1, 128, 28, 28) dtype=float32>, '143': <tf.Tensor 'Relu_5:0' shape=(1, 128, 28, 28) dtype=float32>, '144': <tf.Tensor 'transpose_20:0' shape=(1, 128, 28, 28) dtype=float32>, '145': <tf.Tensor 'batchnorm_6/add_1:0' shape=(1, 128, 28, 28) dtype=float32>, '146': <tf.Tensor 'transpose_23:0' shape=(1, 128, 28, 28) dtype=float32>, '147': <tf.Tensor 'batchnorm_7/add_1:0' shape=(1, 128, 28, 28) dtype=float32>, '148': <tf.Tensor 'Add_2:0' shape=(1, 128, 28, 28) dtype=float32>, '149': <tf.Tensor 'Relu_6:0' shape=(1, 128, 28, 28) dtype=float32>, '150': <tf.Tensor 'transpose_26:0' shape=(1, 128, 28, 28) dtype=float32>, '151': <tf.Tensor 'batchnorm_8/add_1:0' shape=(1, 128, 28, 28) dtype=float32>, '152': <tf.Tensor 'Relu_7:0' shape=(1, 128, 28, 28) dtype=float32>, '153': <tf.Tensor 'transpose_29:0' shape=(1, 128, 28, 28) dtype=float32>, '154': <tf.Tensor 'batchnorm_9/add_1:0' shape=(1, 128, 28, 28) dtype=float32>, '155': <tf.Tensor 'Add_3:0' shape=(1, 128, 28, 28) dtype=float32>, '156': <tf.Tensor 'Relu_8:0' shape=(1, 128, 28, 28) dtype=float32>, '157': <tf.Tensor 'transpose_32:0' shape=(1, 256, 14, 14) dtype=float32>, '158': <tf.Tensor 'batchnorm_10/add_1:0' shape=(1, 256, 14, 14) dtype=float32>, '159': <tf.Tensor 'Relu_9:0' shape=(1, 256, 14, 14) dtype=float32>, '160': <tf.Tensor 'transpose_35:0' shape=(1, 256, 14, 14) dtype=float32>, '161': <tf.Tensor 'batchnorm_11/add_1:0' shape=(1, 256, 14, 14) dtype=float32>, '162': <tf.Tensor 'transpose_38:0' shape=(1, 256, 14, 14) dtype=float32>, '163': <tf.Tensor 'batchnorm_12/add_1:0' shape=(1, 256, 14, 14) dtype=float32>, '164': <tf.Tensor 'Add_4:0' shape=(1, 256, 14, 14) dtype=float32>, '165': <tf.Tensor 'Relu_10:0' shape=(1, 256, 14, 14) dtype=float32>, '166': <tf.Tensor 'transpose_41:0' shape=(1, 256, 14, 14) dtype=float32>, '167': <tf.Tensor 'batchnorm_13/add_1:0' shape=(1, 256, 14, 14) dtype=float32>, '168': <tf.Tensor 'Relu_11:0' shape=(1, 256, 14, 14) dtype=float32>, '169': <tf.Tensor 'transpose_44:0' shape=(1, 256, 14, 14) dtype=float32>, '170': <tf.Tensor 'batchnorm_14/add_1:0' shape=(1, 256, 14, 14) dtype=float32>, '171': <tf.Tensor 'Add_5:0' shape=(1, 256, 14, 14) dtype=float32>, '172': <tf.Tensor 'Relu_12:0' shape=(1, 256, 14, 14) dtype=float32>, '173': <tf.Tensor 'transpose_47:0' shape=(1, 512, 7, 7) dtype=float32>, '174': <tf.Tensor 'batchnorm_15/add_1:0' shape=(1, 512, 7, 7) dtype=float32>, '175': <tf.Tensor 'Relu_13:0' shape=(1, 512, 7, 7) dtype=float32>, '176': <tf.Tensor 'transpose_50:0' shape=(1, 512, 7, 7) dtype=float32>, '177': <tf.Tensor 'batchnorm_16/add_1:0' shape=(1, 512, 7, 7) dtype=float32>, '178': <tf.Tensor 'transpose_53:0' shape=(1, 512, 7, 7) dtype=float32>, '179': <tf.Tensor 'batchnorm_17/add_1:0' shape=(1, 512, 7, 7) dtype=float32>, '180': <tf.Tensor 'Add_6:0' shape=(1, 512, 7, 7) dtype=float32>, '181': <tf.Tensor 'Relu_14:0' shape=(1, 512, 7, 7) dtype=float32>, '182': <tf.Tensor 'transpose_56:0' shape=(1, 512, 7, 7) dtype=float32>, '183': <tf.Tensor 'batchnorm_18/add_1:0' shape=(1, 512, 7, 7) dtype=float32>, '184': <tf.Tensor 'Relu_15:0' shape=(1, 512, 7, 7) dtype=float32>, '185': <tf.Tensor 'transpose_59:0' shape=(1, 512, 7, 7) dtype=float32>, '186': <tf.Tensor 'batchnorm_19/add_1:0' shape=(1, 512, 7, 7) dtype=float32>, '187': <tf.Tensor 'Add_7:0' shape=(1, 512, 7, 7) dtype=float32>, '188': <tf.Tensor 'Relu_16:0' shape=(1, 512, 7, 7) dtype=float32>, '189': <tf.Tensor 'Mean:0' shape=(1, 512, 1, 1) dtype=float32>, '190': <tf.Tensor 'flatten/Reshape:0' shape=(1, 512) dtype=float32>, '191': <tf.Tensor 'add_8:0' shape=(1, 85) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "from onnx_tf.backend import prepare\n",
    "import onnx\n",
    "# load the model saved in onnx format\n",
    "model_onnx = onnx.load('model_best.onnx')\n",
    "# prepare model for exporting to tensorFlow using tensorFlow backend\n",
    "tf_rep = prepare(model_onnx)\n",
    "feature = torch.rand(1, 3, 224, 224)\n",
    "print(tf_rep.run(feature)) # run sample inference of your model\n",
    "print(tf_rep.inputs) # Input nodes to the model\n",
    "print('-----')\n",
    "print(tf_rep.outputs) # Output nodes from the model\n",
    "print('-----')\n",
    "print(tf_rep.tensor_dict) # All nodes in the model\n",
    "\n",
    "# export tensorFlow backend to tensorflow tf file\n",
    "tf_rep.export_graph('model_best.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
