{"cells":[{"metadata":{},"cell_type":"markdown","source":"# ResNet 16"},{"metadata":{},"cell_type":"markdown","source":"## Configurations"},{"metadata":{},"cell_type":"markdown","source":"### Path exploring\n* Img Location\n`/kaggle/input/daanforestpark/_/DaanForestPark/_/_/_.jpg`\n* Label Location\n`/kaggle/input/daanforestpark/label2.csv`"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" Show all the data path here \"\"\"\n\"\"\" you need to define your datapath \"\"\"\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Install and import necessary libraries\nFirst, you need to load required package as the following so that we can start enjoying this journey."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\nfrom PIL import Image\n\nimport os\nimport random\nfrom datetime import datetime\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader,SubsetRandomSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.tensorboard import SummaryWriter\n\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torchsummary import summary","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"假設沒有套件,打開下方Console，輸入`pip install xxx` e.g., `pip install torchsummary`"},{"metadata":{},"cell_type":"markdown","source":"#### GPU or not?\n如果你本地有GPU，建議安裝cuda來做訓練。如果是在Kaggle的環境上訓練，可以開啟右側直欄的`Accelerator`，裡面有使用GPU or TPU options."},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Path specified\n##### Where is the Data in Kaggle ?\n在一開始就有找到所有data的路徑，如果不是很確定就uncomment `# print` 再run一次看看，它會顯示data的location.\n右邊直欄也有`Data`可以讓你檢查資料的位置。"},{"metadata":{"trusted":true},"cell_type":"code","source":"# the path of .csv file\nDATA_DIR = '/kaggle/input/daanforestpark'\nLABEL_DIR = os.path.join(DATA_DIR, 'label2.csv')\nIMAGE_DIR = DATA_DIR # since all data were located in the same directory.","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameters"},{"metadata":{},"cell_type":"markdown","source":"這裡是模型需要調整的參數，盡量不要做更動。"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_WORKERS = 4\n\nEPOCHES = 50\nBATCH_SIZE = 32\nPATIENCE = 5\nSPLIT_VALID = .2\nLR = 1e-2\nL1_ratio = 1e-4\nL2_ratio = 1e-3","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Augmentation "},{"metadata":{"trusted":true},"cell_type":"code","source":"# ToPILImage() -> Resize() -> ToTensor()\ntransform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.RandomCrop(224),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.3),\n#         transforms.ColorJitter(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])        \n        ])","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define the DataSet and the DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, image_dir, label_dir, transform=None):\n        _images, _labels = [], []\n        # total amount of dataset \n        _number = 0\n        # Reading the categorical file\n        label_df = pd.read_csv(label_dir)\n        \n        # Iterate all files including .jpg inages  \n        for subdir, dirs, files in tqdm(os.walk(image_dir)):\n            for filename in files:\n                if len(subdir.split(os.sep)) >5:\n                    # 注意到這裡如果不能讀檔一定是這裡發生問題,路徑要檢查一下\n                    corr_label = label_df[label_df['dirpath']==os.sep.join(subdir.split(os.sep)[5:])]['label'].values\n                    if corr_label.size!= 0 and filename.endswith(('jpg')):\n                        _images.append(subdir + os.sep + filename)\n                        _labels.append(corr_label)\n                        _number+=1\n        # Randomly arrange data pairs\n        mapIndexPosition = list(zip(_images, _labels))\n        random.shuffle(mapIndexPosition)\n        _images, _labels = zip(*mapIndexPosition)\n\n        self._image = iter(_images)\n        self._labels = iter(_labels)\n        self._number = _number\n        self._category = label_df['label'].nunique()\n        self.transform = transform\n        \n    def __len__(self):\n        return self._number\n\n    def __getitem__(self, index):    \n        img = next(self._image)\n        lab = next(self._labels)\n        \n        img = self._loadimage(img)\n        if self.transform:\n            img = self.transform(img)        \n        return img, lab\n     \n    def _categorical(self, label):\n        return np.arange(self._category) == label[:,None]\n    \n    def _loadimage(self, file):\n        return Image.open(file).convert('RGB')\n    \n    def get_categorical_nums(self):\n        return self._category\n    ","execution_count":15,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_dataset = MyDataset(IMAGE_DIR, LABEL_DIR, transform=transform)\n\nvalid_size = SPLIT_VALID\nnum_train = len(train_dataset)\nindices = list(range(num_train))\nsplit = int(np.floor(valid_size * num_train))\ntrain_idx, valid_idx = indices[split:], indices[:split]\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=train_sampler, drop_last=True)\nvalid_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=valid_sampler, drop_last=True)","execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cf5767786174396b9e9a5387bc78b1e"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### ResNet18"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = SimpleCNN(train_dataset.get_categorical_nums()).to(device)\nmodel_ft = models.resnet18(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, train_dataset.get_categorical_nums())","execution_count":17,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n","name":"stderr"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ff23a5ee15949fb86c62833f51775de"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# channels, H, W\nmodel = model_ft.to(device=device)\nsummary(model, input_size=(3, 64, 64))","execution_count":18,"outputs":[{"output_type":"stream","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 64, 64]           9,408\n       BatchNorm2d-2           [-1, 64, 64, 64]             128\n              ReLU-3           [-1, 64, 64, 64]               0\n         MaxPool2d-4           [-1, 64, 32, 32]               0\n            Conv2d-5           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-6           [-1, 64, 32, 32]             128\n              ReLU-7           [-1, 64, 32, 32]               0\n            Conv2d-8           [-1, 64, 32, 32]          36,864\n       BatchNorm2d-9           [-1, 64, 32, 32]             128\n             ReLU-10           [-1, 64, 32, 32]               0\n       BasicBlock-11           [-1, 64, 32, 32]               0\n           Conv2d-12           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-13           [-1, 64, 32, 32]             128\n             ReLU-14           [-1, 64, 32, 32]               0\n           Conv2d-15           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-16           [-1, 64, 32, 32]             128\n             ReLU-17           [-1, 64, 32, 32]               0\n       BasicBlock-18           [-1, 64, 32, 32]               0\n           Conv2d-19           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-20           [-1, 64, 32, 32]             128\n             ReLU-21           [-1, 64, 32, 32]               0\n           Conv2d-22           [-1, 64, 32, 32]          36,864\n      BatchNorm2d-23           [-1, 64, 32, 32]             128\n             ReLU-24           [-1, 64, 32, 32]               0\n       BasicBlock-25           [-1, 64, 32, 32]               0\n           Conv2d-26          [-1, 128, 16, 16]          73,728\n      BatchNorm2d-27          [-1, 128, 16, 16]             256\n             ReLU-28          [-1, 128, 16, 16]               0\n           Conv2d-29          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-30          [-1, 128, 16, 16]             256\n           Conv2d-31          [-1, 128, 16, 16]           8,192\n      BatchNorm2d-32          [-1, 128, 16, 16]             256\n             ReLU-33          [-1, 128, 16, 16]               0\n       BasicBlock-34          [-1, 128, 16, 16]               0\n           Conv2d-35          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-36          [-1, 128, 16, 16]             256\n             ReLU-37          [-1, 128, 16, 16]               0\n           Conv2d-38          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-39          [-1, 128, 16, 16]             256\n             ReLU-40          [-1, 128, 16, 16]               0\n       BasicBlock-41          [-1, 128, 16, 16]               0\n           Conv2d-42          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-43          [-1, 128, 16, 16]             256\n             ReLU-44          [-1, 128, 16, 16]               0\n           Conv2d-45          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-46          [-1, 128, 16, 16]             256\n             ReLU-47          [-1, 128, 16, 16]               0\n       BasicBlock-48          [-1, 128, 16, 16]               0\n           Conv2d-49          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-50          [-1, 128, 16, 16]             256\n             ReLU-51          [-1, 128, 16, 16]               0\n           Conv2d-52          [-1, 128, 16, 16]         147,456\n      BatchNorm2d-53          [-1, 128, 16, 16]             256\n             ReLU-54          [-1, 128, 16, 16]               0\n       BasicBlock-55          [-1, 128, 16, 16]               0\n           Conv2d-56            [-1, 256, 8, 8]         294,912\n      BatchNorm2d-57            [-1, 256, 8, 8]             512\n             ReLU-58            [-1, 256, 8, 8]               0\n           Conv2d-59            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-60            [-1, 256, 8, 8]             512\n           Conv2d-61            [-1, 256, 8, 8]          32,768\n      BatchNorm2d-62            [-1, 256, 8, 8]             512\n             ReLU-63            [-1, 256, 8, 8]               0\n       BasicBlock-64            [-1, 256, 8, 8]               0\n           Conv2d-65            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-66            [-1, 256, 8, 8]             512\n             ReLU-67            [-1, 256, 8, 8]               0\n           Conv2d-68            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-69            [-1, 256, 8, 8]             512\n             ReLU-70            [-1, 256, 8, 8]               0\n       BasicBlock-71            [-1, 256, 8, 8]               0\n           Conv2d-72            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-73            [-1, 256, 8, 8]             512\n             ReLU-74            [-1, 256, 8, 8]               0\n           Conv2d-75            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-76            [-1, 256, 8, 8]             512\n             ReLU-77            [-1, 256, 8, 8]               0\n       BasicBlock-78            [-1, 256, 8, 8]               0\n           Conv2d-79            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-80            [-1, 256, 8, 8]             512\n             ReLU-81            [-1, 256, 8, 8]               0\n           Conv2d-82            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-83            [-1, 256, 8, 8]             512\n             ReLU-84            [-1, 256, 8, 8]               0\n       BasicBlock-85            [-1, 256, 8, 8]               0\n           Conv2d-86            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-87            [-1, 256, 8, 8]             512\n             ReLU-88            [-1, 256, 8, 8]               0\n           Conv2d-89            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-90            [-1, 256, 8, 8]             512\n             ReLU-91            [-1, 256, 8, 8]               0\n       BasicBlock-92            [-1, 256, 8, 8]               0\n           Conv2d-93            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-94            [-1, 256, 8, 8]             512\n             ReLU-95            [-1, 256, 8, 8]               0\n           Conv2d-96            [-1, 256, 8, 8]         589,824\n      BatchNorm2d-97            [-1, 256, 8, 8]             512\n             ReLU-98            [-1, 256, 8, 8]               0\n       BasicBlock-99            [-1, 256, 8, 8]               0\n          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n            ReLU-102            [-1, 512, 4, 4]               0\n          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n          Conv2d-105            [-1, 512, 4, 4]         131,072\n     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n            ReLU-107            [-1, 512, 4, 4]               0\n      BasicBlock-108            [-1, 512, 4, 4]               0\n          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n            ReLU-111            [-1, 512, 4, 4]               0\n          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n            ReLU-114            [-1, 512, 4, 4]               0\n      BasicBlock-115            [-1, 512, 4, 4]               0\n          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n            ReLU-118            [-1, 512, 4, 4]               0\n          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n            ReLU-121            [-1, 512, 4, 4]               0\n      BasicBlock-122            [-1, 512, 4, 4]               0\nAdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n          Linear-124                   [-1, 85]          43,605\n================================================================\nTotal params: 21,328,277\nTrainable params: 21,328,277\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.19\nForward/backward pass size (MB): 31.44\nParams size (MB): 81.36\nEstimated Total Size (MB): 112.99\n----------------------------------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_checkpoint(model, state, filename, ckptname='resNet.ckpt'):\n    if not os.path.isdir(filename):\n        try: \n            os.mkdir(filename) \n            print('Create {}'.format(filename))\n        except OSError as err: \n            raise err\n\n    _ckpt = os.path.join(filename, ckptname)\n    torch.save(state, _ckpt)\n    print('Saving the {} in {}'.format(ckptname, filename))\n\n    \"\"\" If you wwanna save the whole model, Uncomment below \"\"\"\n#     _model = os.path.join(filename, 'model_best.ckpt')\n#     torch.save(model, _model)","execution_count":20,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=0, verbose=True)\nschedulerAcc = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.9, patience=0, verbose=True)\ncriterion = nn.CrossEntropyLoss().to(device=device)\n\n# early stopping\nmin_val_loss = np.Inf\npatience = PATIENCE\nglobal_step = 1\n\n# build the writer file\nwrite_file = 'runs/experiment_{}'.format(datetime.now().strftime('%f'))\nwriter = SummaryWriter(write_file)\n# define the ckpt path\nwriter_ckpt_path = os.path.join(write_file, 'ckpt')\n\nmodel_ft.train()\n\nfor epoch in range(EPOCHES):\n    for i, (img_batch, label_batch) in tqdm(enumerate(train_loader)):    \n        optimizer.zero_grad()      \n        img_batch = img_batch.to(device=device)\n        label_batch = label_batch.to(device=device)  \n        output = model_ft(img_batch)\n        loss = criterion(output, label_batch.squeeze())\n        \n        # l2 Regularization loss\n        l2_regularization = 0\n        l1_regularization = 0\n        for p in model.parameters():\n            l1_regularization += torch.norm(p, 1)\n            l2_regularization += torch.norm(p, 2)\n#         loss = loss + (L1_ratio * l1_regularization) + (L2_ratio * l2_regularization)\n        loss = loss + (L2_ratio * l2_regularization)\n\n        loss.backward()\n        # clip the grandient value for avoiding explosion\n        nn.utils.clip_grad_norm_(model.parameters(), 0.9) \n        optimizer.step()\n\n        # Compute accuracy\n        _, predicted = torch.max(output.cpu().data, 1)\n        accuracy = torch.sum(predicted == label_batch.cpu().data.view(-1), dtype=torch.float32) / BATCH_SIZE\n        \n        # Write tensorboard\n        writer.add_scalar('train/Accuracy', accuracy.item(), global_step)\n        writer.add_scalar('train/Loss', loss.item(), global_step)\n        writer.add_scalar('train/L1RegLoss', l1_regularization.item(), global_step)\n        writer.add_scalar('train/L2RegLoss', l2_regularization.item(), global_step)\n        writer.add_scalar('train/LR', get_lr(optimizer), global_step)\n                \n        global_step += 1\n        \n        if i % 50== 0:\n            print('epoch {}, step {}, \\\n            total_loss={:.3f}, \\\n            accuracy={:.3f}'.format(epoch+1, i, loss.item(), accuracy.item()))\n    \n    \n    print('--- Validation phase ---')\n    eval_loss = 0\n    with torch.no_grad():\n        for i, (img_batch, label_batch) in enumerate(valid_loader):\n            output = model(img_batch.to(device))\n            _, predicted = torch.max(output.cpu().data, 1)\n            loss = criterion(output, label_batch.to(device).squeeze())\n            accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n            eval_loss += loss.item()\n            \n            # Write tensorboard\n            for cat in range(train_dataset.get_categorical_nums()):\n                writer.add_pr_curve('valid/pr_curve', (label_batch == cat).int().squeeze(),\n                                    (predicted == cat).int().squeeze(), epoch*len(valid_loader)+i)\n#             writer.add_images('valid/image_batch', img_batch, epoch*len(valid_loader)+i)\n            writer.add_scalar('valid/Accuracy', accuracy.item(), epoch*len(valid_loader)+i)\n            writer.add_scalar('valid/Loss', loss.item(), epoch*len(valid_loader)+i)\n    \n    eval_loss = eval_loss / len(valid_loader)\n    \n    scheduler.step(eval_loss)\n    schedulerAcc.step(eval_loss)\n    \n    print('epoch {}, val_loss={:.3f}'.format(epoch+1, eval_loss))\n\n    ## Early Stopping\n    if eval_loss <= min_val_loss:\n        \n        \"\"\" file path you should define it => 'ckpt/resNet_{}.ckpt' \"\"\"\n        save_checkpoint(model, \n            {\n            'epoch': epoch+1,\n            'state_dict': model.state_dict(),\n            'best_loss': eval_loss,\n            'optimizer' :optimizer.state_dict(),\n            }, writer_ckpt_path)\n        min_val_loss = eval_loss\n    else:\n        patience-=1\n    if patience == 0:\n        print('Early stopping')\n        break\n\nwriter.close()\nprint('Finish all training !')","execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ab1b7ab70a3484fb5afcfda08cf45dc"}},"metadata":{}},{"output_type":"stream","text":"epoch 1, step 0,             total_loss=30.513,             accuracy=0.000\nepoch 1, step 50,             total_loss=17.082,             accuracy=0.188\nepoch 1, step 100,             total_loss=15.108,             accuracy=0.000\nepoch 1, step 150,             total_loss=13.228,             accuracy=0.188\nepoch 1, step 200,             total_loss=13.038,             accuracy=0.188\nepoch 1, step 250,             total_loss=11.348,             accuracy=0.281\nepoch 1, step 300,             total_loss=9.767,             accuracy=0.125\nepoch 1, step 350,             total_loss=9.822,             accuracy=0.094\nepoch 1, step 400,             total_loss=8.677,             accuracy=0.188\nepoch 1, step 450,             total_loss=9.051,             accuracy=0.312\nepoch 1, step 500,             total_loss=8.352,             accuracy=0.219\n\n--- Validation phase ---\nepoch 1, val_loss=3.092\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148c2723cf084bc18cfd2d4f98d1c587"}},"metadata":{}},{"output_type":"stream","text":"epoch 2, step 0,             total_loss=8.888,             accuracy=0.219\nepoch 2, step 50,             total_loss=6.795,             accuracy=0.281\nepoch 2, step 100,             total_loss=7.222,             accuracy=0.188\nepoch 2, step 150,             total_loss=7.078,             accuracy=0.406\nepoch 2, step 200,             total_loss=7.544,             accuracy=0.281\nepoch 2, step 250,             total_loss=6.406,             accuracy=0.469\nepoch 2, step 300,             total_loss=6.197,             accuracy=0.438\nepoch 2, step 350,             total_loss=6.972,             accuracy=0.250\nepoch 2, step 400,             total_loss=7.076,             accuracy=0.375\nepoch 2, step 450,             total_loss=8.541,             accuracy=0.250\nepoch 2, step 500,             total_loss=6.388,             accuracy=0.344\n\n--- Validation phase ---\nEpoch     2: reducing learning rate of group 0 to 9.0000e-03.\nepoch 2, val_loss=2.372\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b0966c4fda3443db6b8c8e3810d8fd6"}},"metadata":{}},{"output_type":"stream","text":"epoch 3, step 0,             total_loss=6.437,             accuracy=0.281\nepoch 3, step 50,             total_loss=5.619,             accuracy=0.406\nepoch 3, step 100,             total_loss=6.342,             accuracy=0.312\nepoch 3, step 150,             total_loss=5.729,             accuracy=0.375\nepoch 3, step 200,             total_loss=5.997,             accuracy=0.250\nepoch 3, step 250,             total_loss=5.841,             accuracy=0.469\nepoch 3, step 300,             total_loss=5.073,             accuracy=0.531\nepoch 3, step 350,             total_loss=6.033,             accuracy=0.344\nepoch 3, step 400,             total_loss=5.431,             accuracy=0.375\nepoch 3, step 450,             total_loss=7.974,             accuracy=0.625\nepoch 3, step 500,             total_loss=5.594,             accuracy=0.438\n\n--- Validation phase ---\nEpoch     3: reducing learning rate of group 0 to 8.1000e-03.\nepoch 3, val_loss=1.999\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1f3863411d843b983786ac72f50ea1f"}},"metadata":{}},{"output_type":"stream","text":"epoch 4, step 0,             total_loss=6.188,             accuracy=0.312\nepoch 4, step 50,             total_loss=5.411,             accuracy=0.562\nepoch 4, step 100,             total_loss=6.232,             accuracy=0.500\nepoch 4, step 150,             total_loss=5.291,             accuracy=0.594\nepoch 4, step 200,             total_loss=5.405,             accuracy=0.375\nepoch 4, step 250,             total_loss=4.790,             accuracy=0.500\nepoch 4, step 300,             total_loss=4.483,             accuracy=0.562\nepoch 4, step 350,             total_loss=6.127,             accuracy=0.500\nepoch 4, step 400,             total_loss=5.151,             accuracy=0.500\nepoch 4, step 450,             total_loss=6.257,             accuracy=0.469\nepoch 4, step 500,             total_loss=4.717,             accuracy=0.531\n\n--- Validation phase ---\nEpoch     4: reducing learning rate of group 0 to 7.2900e-03.\nepoch 4, val_loss=1.726\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47536db2dc934e2eb552a503f792672e"}},"metadata":{}},{"output_type":"stream","text":"epoch 5, step 0,             total_loss=5.539,             accuracy=0.406\nepoch 5, step 50,             total_loss=5.141,             accuracy=0.500\nepoch 5, step 100,             total_loss=5.241,             accuracy=0.312\nepoch 5, step 150,             total_loss=4.443,             accuracy=0.625\nepoch 5, step 200,             total_loss=4.580,             accuracy=0.500\nepoch 5, step 250,             total_loss=5.307,             accuracy=0.562\nepoch 5, step 300,             total_loss=3.910,             accuracy=0.688\nepoch 5, step 350,             total_loss=5.072,             accuracy=0.438\nepoch 5, step 400,             total_loss=4.795,             accuracy=0.438\nepoch 5, step 450,             total_loss=6.101,             accuracy=0.594\nepoch 5, step 500,             total_loss=4.754,             accuracy=0.625\n\n--- Validation phase ---\nEpoch     5: reducing learning rate of group 0 to 6.5610e-03.\nepoch 5, val_loss=1.530\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7118b49249c44f5d981498e31892ed86"}},"metadata":{}},{"output_type":"stream","text":"epoch 6, step 0,             total_loss=4.761,             accuracy=0.500\nepoch 6, step 50,             total_loss=3.898,             accuracy=0.625\nepoch 6, step 100,             total_loss=5.784,             accuracy=0.406\nepoch 6, step 150,             total_loss=4.215,             accuracy=0.625\nepoch 6, step 200,             total_loss=4.181,             accuracy=0.469\nepoch 6, step 250,             total_loss=4.417,             accuracy=0.625\nepoch 6, step 300,             total_loss=3.625,             accuracy=0.656\nepoch 6, step 350,             total_loss=3.899,             accuracy=0.594\nepoch 6, step 400,             total_loss=4.197,             accuracy=0.500\nepoch 6, step 450,             total_loss=5.310,             accuracy=0.531\nepoch 6, step 500,             total_loss=4.260,             accuracy=0.594\n\n--- Validation phase ---\nEpoch     6: reducing learning rate of group 0 to 5.9049e-03.\nepoch 6, val_loss=1.373\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"214a08446f294abab72854c4b934b528"}},"metadata":{}},{"output_type":"stream","text":"epoch 7, step 0,             total_loss=4.182,             accuracy=0.375\nepoch 7, step 50,             total_loss=3.788,             accuracy=0.625\nepoch 7, step 100,             total_loss=4.596,             accuracy=0.500\nepoch 7, step 150,             total_loss=3.570,             accuracy=0.688\nepoch 7, step 200,             total_loss=3.817,             accuracy=0.594\nepoch 7, step 250,             total_loss=4.018,             accuracy=0.594\nepoch 7, step 300,             total_loss=3.001,             accuracy=0.750\nepoch 7, step 350,             total_loss=4.070,             accuracy=0.531\nepoch 7, step 400,             total_loss=3.997,             accuracy=0.500\nepoch 7, step 450,             total_loss=4.241,             accuracy=0.750\nepoch 7, step 500,             total_loss=3.715,             accuracy=0.656\n\n--- Validation phase ---\nEpoch     7: reducing learning rate of group 0 to 5.3144e-03.\nepoch 7, val_loss=1.242\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ce2b79a20b54b418c10e4f6679aad59"}},"metadata":{}},{"output_type":"stream","text":"epoch 8, step 0,             total_loss=3.990,             accuracy=0.594\nepoch 8, step 50,             total_loss=3.649,             accuracy=0.500\nepoch 8, step 100,             total_loss=3.692,             accuracy=0.594\nepoch 8, step 150,             total_loss=3.198,             accuracy=0.750\nepoch 8, step 200,             total_loss=3.328,             accuracy=0.688\nepoch 8, step 250,             total_loss=3.165,             accuracy=0.719\nepoch 8, step 300,             total_loss=3.482,             accuracy=0.688\nepoch 8, step 350,             total_loss=2.790,             accuracy=0.688\nepoch 8, step 400,             total_loss=3.798,             accuracy=0.562\nepoch 8, step 450,             total_loss=4.398,             accuracy=0.594\nepoch 8, step 500,             total_loss=3.866,             accuracy=0.625\n\n--- Validation phase ---\nEpoch     8: reducing learning rate of group 0 to 4.7830e-03.\nepoch 8, val_loss=1.148\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16aeacab54b44e6e973e882bf9fc77d6"}},"metadata":{}},{"output_type":"stream","text":"epoch 9, step 0,             total_loss=3.406,             accuracy=0.688\nepoch 9, step 50,             total_loss=3.622,             accuracy=0.625\nepoch 9, step 100,             total_loss=4.077,             accuracy=0.625\nepoch 9, step 150,             total_loss=2.813,             accuracy=0.688\nepoch 9, step 200,             total_loss=3.440,             accuracy=0.594\nepoch 9, step 250,             total_loss=2.904,             accuracy=0.781\nepoch 9, step 300,             total_loss=2.795,             accuracy=0.906\nepoch 9, step 350,             total_loss=3.029,             accuracy=0.656\nepoch 9, step 400,             total_loss=3.250,             accuracy=0.594\nepoch 9, step 450,             total_loss=4.614,             accuracy=0.562\nepoch 9, step 500,             total_loss=3.238,             accuracy=0.719\n\n--- Validation phase ---\nEpoch     9: reducing learning rate of group 0 to 4.3047e-03.\nepoch 9, val_loss=1.046\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bfc0226237d43f9bd8c402739714736"}},"metadata":{}},{"output_type":"stream","text":"epoch 10, step 0,             total_loss=3.553,             accuracy=0.750\nepoch 10, step 50,             total_loss=3.044,             accuracy=0.594\nepoch 10, step 100,             total_loss=3.394,             accuracy=0.719\nepoch 10, step 150,             total_loss=2.825,             accuracy=0.781\nepoch 10, step 200,             total_loss=3.136,             accuracy=0.750\nepoch 10, step 250,             total_loss=2.864,             accuracy=0.688\nepoch 10, step 300,             total_loss=2.956,             accuracy=0.781\nepoch 10, step 350,             total_loss=2.742,             accuracy=0.719\nepoch 10, step 400,             total_loss=3.105,             accuracy=0.625\nepoch 10, step 450,             total_loss=3.557,             accuracy=0.750\nepoch 10, step 500,             total_loss=3.045,             accuracy=0.625\n\n--- Validation phase ---\nEpoch    10: reducing learning rate of group 0 to 3.8742e-03.\nepoch 10, val_loss=0.935\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a875fa8f2d403e900c66e26ddff4fc"}},"metadata":{}},{"output_type":"stream","text":"epoch 11, step 0,             total_loss=2.765,             accuracy=0.719\nepoch 11, step 50,             total_loss=3.081,             accuracy=0.625\nepoch 11, step 100,             total_loss=3.387,             accuracy=0.594\nepoch 11, step 150,             total_loss=2.540,             accuracy=0.781\nepoch 11, step 200,             total_loss=2.631,             accuracy=0.781\nepoch 11, step 250,             total_loss=3.008,             accuracy=0.750\nepoch 11, step 300,             total_loss=2.436,             accuracy=0.906\nepoch 11, step 350,             total_loss=2.465,             accuracy=0.875\nepoch 11, step 400,             total_loss=3.174,             accuracy=0.656\nepoch 11, step 450,             total_loss=3.025,             accuracy=0.719\nepoch 11, step 500,             total_loss=2.798,             accuracy=0.688\n\n--- Validation phase ---\nEpoch    11: reducing learning rate of group 0 to 3.4868e-03.\nepoch 11, val_loss=0.917\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d773b8da8f954249aa6168f07e215760"}},"metadata":{}},{"output_type":"stream","text":"epoch 12, step 0,             total_loss=3.178,             accuracy=0.562\nepoch 12, step 50,             total_loss=2.692,             accuracy=0.688\nepoch 12, step 100,             total_loss=2.873,             accuracy=0.812\nepoch 12, step 150,             total_loss=2.542,             accuracy=0.812\nepoch 12, step 200,             total_loss=2.521,             accuracy=0.719\nepoch 12, step 250,             total_loss=2.272,             accuracy=0.906\nepoch 12, step 300,             total_loss=2.394,             accuracy=0.844\nepoch 12, step 350,             total_loss=2.742,             accuracy=0.688\nepoch 12, step 400,             total_loss=3.460,             accuracy=0.594\nepoch 12, step 450,             total_loss=3.212,             accuracy=0.781\nepoch 12, step 500,             total_loss=2.330,             accuracy=0.781\n\n--- Validation phase ---\nEpoch    12: reducing learning rate of group 0 to 3.1381e-03.\nepoch 12, val_loss=0.821\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be3e6ae66d90474e83f47b2031fdb63c"}},"metadata":{}},{"output_type":"stream","text":"epoch 13, step 0,             total_loss=2.509,             accuracy=0.688\nepoch 13, step 50,             total_loss=2.565,             accuracy=0.812\nepoch 13, step 100,             total_loss=2.696,             accuracy=0.750\nepoch 13, step 150,             total_loss=2.699,             accuracy=0.750\nepoch 13, step 200,             total_loss=2.526,             accuracy=0.719\nepoch 13, step 250,             total_loss=2.262,             accuracy=0.812\nepoch 13, step 300,             total_loss=2.171,             accuracy=0.844\nepoch 13, step 350,             total_loss=2.039,             accuracy=0.875\nepoch 13, step 400,             total_loss=2.950,             accuracy=0.594\nepoch 13, step 450,             total_loss=2.507,             accuracy=0.781\nepoch 13, step 500,             total_loss=2.253,             accuracy=0.781\n\n--- Validation phase ---\nEpoch    13: reducing learning rate of group 0 to 2.8243e-03.\nepoch 13, val_loss=0.811\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a9988513914cbc9af0ade9f2770544"}},"metadata":{}},{"output_type":"stream","text":"epoch 14, step 0,             total_loss=2.441,             accuracy=0.750\nepoch 14, step 50,             total_loss=2.317,             accuracy=0.719\nepoch 14, step 100,             total_loss=2.731,             accuracy=0.750\nepoch 14, step 150,             total_loss=2.183,             accuracy=0.844\nepoch 14, step 200,             total_loss=2.378,             accuracy=0.750\nepoch 14, step 250,             total_loss=2.124,             accuracy=0.750\nepoch 14, step 300,             total_loss=2.004,             accuracy=0.875\nepoch 14, step 350,             total_loss=2.023,             accuracy=0.812\nepoch 14, step 400,             total_loss=2.607,             accuracy=0.625\nepoch 14, step 450,             total_loss=2.466,             accuracy=0.844\nepoch 14, step 500,             total_loss=2.505,             accuracy=0.688\n\n--- Validation phase ---\nEpoch    14: reducing learning rate of group 0 to 2.5419e-03.\nepoch 14, val_loss=0.764\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba8e0897a8bd414fae78905ccc5dbe54"}},"metadata":{}},{"output_type":"stream","text":"epoch 15, step 0,             total_loss=2.231,             accuracy=0.812\nepoch 15, step 50,             total_loss=2.238,             accuracy=0.719\nepoch 15, step 100,             total_loss=2.827,             accuracy=0.688\nepoch 15, step 150,             total_loss=1.908,             accuracy=0.906\nepoch 15, step 200,             total_loss=2.306,             accuracy=0.812\nepoch 15, step 250,             total_loss=2.123,             accuracy=0.812\nepoch 15, step 300,             total_loss=1.865,             accuracy=0.875\nepoch 15, step 350,             total_loss=2.004,             accuracy=0.812\nepoch 15, step 400,             total_loss=3.275,             accuracy=0.500\nepoch 15, step 450,             total_loss=2.482,             accuracy=0.812\nepoch 15, step 500,             total_loss=2.031,             accuracy=0.781\n\n--- Validation phase ---\nEpoch    15: reducing learning rate of group 0 to 2.2877e-03.\nepoch 15, val_loss=0.725\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bdecbd7154f44e08f207a27d783661f"}},"metadata":{}},{"output_type":"stream","text":"epoch 16, step 0,             total_loss=2.392,             accuracy=0.656\nepoch 16, step 50,             total_loss=2.170,             accuracy=0.844\nepoch 16, step 100,             total_loss=2.580,             accuracy=0.719\nepoch 16, step 150,             total_loss=1.967,             accuracy=0.844\nepoch 16, step 200,             total_loss=1.998,             accuracy=0.781\nepoch 16, step 250,             total_loss=1.826,             accuracy=0.875\nepoch 16, step 300,             total_loss=2.072,             accuracy=0.781\nepoch 16, step 350,             total_loss=1.748,             accuracy=0.875\nepoch 16, step 400,             total_loss=2.586,             accuracy=0.594\nepoch 16, step 450,             total_loss=2.484,             accuracy=0.781\nepoch 16, step 500,             total_loss=1.812,             accuracy=0.906\n\n--- Validation phase ---\nEpoch    16: reducing learning rate of group 0 to 2.0589e-03.\nepoch 16, val_loss=0.679\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17261f0b399344de8b4901cad2b1799c"}},"metadata":{}},{"output_type":"stream","text":"epoch 17, step 0,             total_loss=1.879,             accuracy=0.844\nepoch 17, step 50,             total_loss=1.997,             accuracy=0.844\nepoch 17, step 100,             total_loss=2.302,             accuracy=0.781\nepoch 17, step 150,             total_loss=1.712,             accuracy=0.938\nepoch 17, step 200,             total_loss=1.908,             accuracy=0.750\nepoch 17, step 250,             total_loss=1.756,             accuracy=0.750\nepoch 17, step 300,             total_loss=1.830,             accuracy=0.844\nepoch 17, step 350,             total_loss=1.883,             accuracy=0.812\nepoch 17, step 400,             total_loss=2.479,             accuracy=0.688\nepoch 17, step 450,             total_loss=2.339,             accuracy=0.719\nepoch 17, step 500,             total_loss=1.843,             accuracy=0.812\n\n--- Validation phase ---\nEpoch    17: reducing learning rate of group 0 to 1.8530e-03.\nepoch 17, val_loss=0.670\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9031f60bed149139b8ad0495ed228e2"}},"metadata":{}},{"output_type":"stream","text":"epoch 18, step 0,             total_loss=1.994,             accuracy=0.781\nepoch 18, step 50,             total_loss=2.120,             accuracy=0.688\nepoch 18, step 100,             total_loss=2.291,             accuracy=0.688\nepoch 18, step 150,             total_loss=1.672,             accuracy=0.844\nepoch 18, step 200,             total_loss=1.894,             accuracy=0.812\nepoch 18, step 250,             total_loss=1.712,             accuracy=0.812\nepoch 18, step 300,             total_loss=1.530,             accuracy=0.844\nepoch 18, step 350,             total_loss=1.374,             accuracy=0.906\nepoch 18, step 400,             total_loss=2.097,             accuracy=0.750\nepoch 18, step 450,             total_loss=2.161,             accuracy=0.781\nepoch 18, step 500,             total_loss=1.879,             accuracy=0.719\n\n--- Validation phase ---\nEpoch    18: reducing learning rate of group 0 to 1.6677e-03.\nEpoch    18: reducing learning rate of group 0 to 1.5009e-03.\nepoch 18, val_loss=0.683\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0336ee8df8684917b157d051a09090b6"}},"metadata":{}},{"output_type":"stream","text":"epoch 19, step 0,             total_loss=1.961,             accuracy=0.750\nepoch 19, step 50,             total_loss=1.666,             accuracy=0.844\nepoch 19, step 100,             total_loss=2.085,             accuracy=0.719\nepoch 19, step 150,             total_loss=1.858,             accuracy=0.781\nepoch 19, step 200,             total_loss=1.572,             accuracy=0.875\nepoch 19, step 250,             total_loss=1.313,             accuracy=0.906\nepoch 19, step 300,             total_loss=1.560,             accuracy=0.844\nepoch 19, step 350,             total_loss=1.470,             accuracy=0.875\nepoch 19, step 400,             total_loss=2.446,             accuracy=0.688\nepoch 19, step 450,             total_loss=1.432,             accuracy=0.938\nepoch 19, step 500,             total_loss=1.542,             accuracy=0.844\n\n--- Validation phase ---\nEpoch    19: reducing learning rate of group 0 to 1.3509e-03.\nepoch 19, val_loss=0.653\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91274ddd4d145838e028df550b7e985"}},"metadata":{}},{"output_type":"stream","text":"epoch 20, step 0,             total_loss=1.729,             accuracy=0.812\nepoch 20, step 50,             total_loss=1.572,             accuracy=0.844\nepoch 20, step 100,             total_loss=2.024,             accuracy=0.688\nepoch 20, step 150,             total_loss=1.800,             accuracy=0.719\nepoch 20, step 200,             total_loss=1.486,             accuracy=0.812\nepoch 20, step 250,             total_loss=1.301,             accuracy=0.906\nepoch 20, step 300,             total_loss=1.393,             accuracy=0.906\nepoch 20, step 350,             total_loss=1.326,             accuracy=0.906\nepoch 20, step 400,             total_loss=2.133,             accuracy=0.625\nepoch 20, step 450,             total_loss=1.800,             accuracy=0.844\nepoch 20, step 500,             total_loss=1.560,             accuracy=0.812\n\n--- Validation phase ---\nEpoch    20: reducing learning rate of group 0 to 1.2158e-03.\nepoch 20, val_loss=0.648\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"607e3bc49d464d439773152b30ee78a0"}},"metadata":{}},{"output_type":"stream","text":"epoch 21, step 0,             total_loss=1.574,             accuracy=0.750\nepoch 21, step 50,             total_loss=1.588,             accuracy=0.844\nepoch 21, step 100,             total_loss=1.794,             accuracy=0.812\nepoch 21, step 150,             total_loss=1.446,             accuracy=0.844\nepoch 21, step 200,             total_loss=1.507,             accuracy=0.750\nepoch 21, step 250,             total_loss=1.550,             accuracy=0.844\nepoch 21, step 300,             total_loss=1.305,             accuracy=0.875\nepoch 21, step 350,             total_loss=1.293,             accuracy=0.906\nepoch 21, step 400,             total_loss=1.739,             accuracy=0.562\nepoch 21, step 450,             total_loss=1.522,             accuracy=0.906\nepoch 21, step 500,             total_loss=1.280,             accuracy=0.906\n\n--- Validation phase ---\nEpoch    21: reducing learning rate of group 0 to 1.0942e-03.\nepoch 21, val_loss=0.593\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9b887cc098a4b778260f06ebbff6646"}},"metadata":{}},{"output_type":"stream","text":"epoch 22, step 0,             total_loss=1.710,             accuracy=0.719\nepoch 22, step 50,             total_loss=1.559,             accuracy=0.812\nepoch 22, step 100,             total_loss=1.708,             accuracy=0.812\nepoch 22, step 150,             total_loss=1.313,             accuracy=0.875\nepoch 22, step 200,             total_loss=1.366,             accuracy=0.906\nepoch 22, step 250,             total_loss=1.298,             accuracy=0.875\nepoch 22, step 300,             total_loss=1.192,             accuracy=0.969\nepoch 22, step 350,             total_loss=1.277,             accuracy=0.875\nepoch 22, step 400,             total_loss=1.564,             accuracy=0.781\nepoch 22, step 450,             total_loss=1.690,             accuracy=0.844\nepoch 22, step 500,             total_loss=1.390,             accuracy=0.812\n\n--- Validation phase ---\nEpoch    22: reducing learning rate of group 0 to 9.8477e-04.\nepoch 22, val_loss=0.564\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fded4980fd0542ae9d110cf51c9e1f02"}},"metadata":{}},{"output_type":"stream","text":"epoch 23, step 0,             total_loss=1.462,             accuracy=0.844\nepoch 23, step 50,             total_loss=1.565,             accuracy=0.688\nepoch 23, step 100,             total_loss=1.756,             accuracy=0.781\nepoch 23, step 150,             total_loss=1.136,             accuracy=0.906\nepoch 23, step 200,             total_loss=1.417,             accuracy=0.781\nepoch 23, step 250,             total_loss=1.222,             accuracy=0.875\nepoch 23, step 300,             total_loss=1.357,             accuracy=0.844\nepoch 23, step 350,             total_loss=1.312,             accuracy=0.750\nepoch 23, step 400,             total_loss=1.696,             accuracy=0.719\nepoch 23, step 450,             total_loss=1.418,             accuracy=0.906\nepoch 23, step 500,             total_loss=1.229,             accuracy=0.844\n\n--- Validation phase ---\nEpoch    23: reducing learning rate of group 0 to 8.8629e-04.\nepoch 23, val_loss=0.546\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff477e94040b4054921fa36cbd448af4"}},"metadata":{}},{"output_type":"stream","text":"epoch 24, step 0,             total_loss=1.317,             accuracy=0.781\nepoch 24, step 50,             total_loss=1.556,             accuracy=0.750\nepoch 24, step 100,             total_loss=1.696,             accuracy=0.781\nepoch 24, step 150,             total_loss=1.336,             accuracy=0.906\nepoch 24, step 200,             total_loss=1.307,             accuracy=0.844\nepoch 24, step 250,             total_loss=1.331,             accuracy=0.844\nepoch 24, step 300,             total_loss=1.421,             accuracy=0.844\nepoch 24, step 350,             total_loss=1.215,             accuracy=0.875\nepoch 24, step 400,             total_loss=1.635,             accuracy=0.750\nepoch 24, step 450,             total_loss=1.387,             accuracy=0.875\nepoch 24, step 500,             total_loss=1.379,             accuracy=0.875\n\n--- Validation phase ---\nEpoch    24: reducing learning rate of group 0 to 7.9766e-04.\nEpoch    24: reducing learning rate of group 0 to 7.1790e-04.\nepoch 24, val_loss=0.558\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0666b09c50db43c198b7751057eb43f0"}},"metadata":{}},{"output_type":"stream","text":"epoch 25, step 0,             total_loss=1.324,             accuracy=0.781\nepoch 25, step 50,             total_loss=1.300,             accuracy=0.812\nepoch 25, step 100,             total_loss=1.601,             accuracy=0.750\nepoch 25, step 150,             total_loss=1.225,             accuracy=0.875\nepoch 25, step 200,             total_loss=1.213,             accuracy=0.875\nepoch 25, step 250,             total_loss=1.120,             accuracy=0.875\nepoch 25, step 300,             total_loss=1.043,             accuracy=0.875\nepoch 25, step 350,             total_loss=0.979,             accuracy=0.969\nepoch 25, step 400,             total_loss=1.902,             accuracy=0.719\nepoch 25, step 450,             total_loss=1.390,             accuracy=0.844\nepoch 25, step 500,             total_loss=1.182,             accuracy=0.906\n\n--- Validation phase ---\nEpoch    25: reducing learning rate of group 0 to 6.4611e-04.\nepoch 25, val_loss=0.528\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e77b57c431a48c481ab12b6326ce1c0"}},"metadata":{}},{"output_type":"stream","text":"epoch 26, step 0,             total_loss=1.269,             accuracy=0.906\nepoch 26, step 50,             total_loss=1.387,             accuracy=0.688\nepoch 26, step 100,             total_loss=1.447,             accuracy=0.812\nepoch 26, step 150,             total_loss=1.209,             accuracy=0.906\nepoch 26, step 200,             total_loss=1.275,             accuracy=0.969\nepoch 26, step 250,             total_loss=1.038,             accuracy=0.906\nepoch 26, step 300,             total_loss=1.094,             accuracy=0.844\nepoch 26, step 350,             total_loss=1.158,             accuracy=0.812\nepoch 26, step 400,             total_loss=1.523,             accuracy=0.719\nepoch 26, step 450,             total_loss=1.233,             accuracy=0.906\nepoch 26, step 500,             total_loss=1.090,             accuracy=0.875\n\n--- Validation phase ---\nEpoch    26: reducing learning rate of group 0 to 5.8150e-04.\nepoch 26, val_loss=0.509\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b4bcd81f97e4d679cd4fd8d6b470714"}},"metadata":{}},{"output_type":"stream","text":"epoch 27, step 0,             total_loss=1.235,             accuracy=0.844\nepoch 27, step 50,             total_loss=1.482,             accuracy=0.812\nepoch 27, step 100,             total_loss=1.597,             accuracy=0.719\nepoch 27, step 150,             total_loss=1.161,             accuracy=0.906\nepoch 27, step 200,             total_loss=1.349,             accuracy=0.812\nepoch 27, step 250,             total_loss=1.120,             accuracy=0.875\nepoch 27, step 300,             total_loss=1.172,             accuracy=0.875\nepoch 27, step 350,             total_loss=1.252,             accuracy=0.844\nepoch 27, step 400,             total_loss=1.564,             accuracy=0.750\nepoch 27, step 450,             total_loss=1.698,             accuracy=0.781\nepoch 27, step 500,             total_loss=0.984,             accuracy=0.938\n\n--- Validation phase ---\nEpoch    27: reducing learning rate of group 0 to 5.2335e-04.\nEpoch    27: reducing learning rate of group 0 to 4.7101e-04.\nepoch 27, val_loss=0.512\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983af16a61624fff88cd9acb3a35d6a6"}},"metadata":{}},{"output_type":"stream","text":"epoch 28, step 0,             total_loss=1.074,             accuracy=0.969\nepoch 28, step 50,             total_loss=1.314,             accuracy=0.781\nepoch 28, step 100,             total_loss=1.520,             accuracy=0.719\nepoch 28, step 150,             total_loss=1.291,             accuracy=0.750\nepoch 28, step 200,             total_loss=1.127,             accuracy=0.875\nepoch 28, step 250,             total_loss=1.068,             accuracy=0.938\nepoch 28, step 300,             total_loss=0.974,             accuracy=0.938\nepoch 28, step 350,             total_loss=1.028,             accuracy=0.938\nepoch 28, step 400,             total_loss=1.222,             accuracy=0.812\nepoch 28, step 450,             total_loss=1.282,             accuracy=0.844\nepoch 28, step 500,             total_loss=1.287,             accuracy=0.844\n\n--- Validation phase ---\nEpoch    28: reducing learning rate of group 0 to 4.2391e-04.\nepoch 28, val_loss=0.486\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a2ccdef0cff4926a452c144c53e0720"}},"metadata":{}},{"output_type":"stream","text":"epoch 29, step 0,             total_loss=1.030,             accuracy=0.969\nepoch 29, step 50,             total_loss=1.094,             accuracy=0.906\nepoch 29, step 100,             total_loss=1.287,             accuracy=0.812\nepoch 29, step 150,             total_loss=1.120,             accuracy=0.844\nepoch 29, step 200,             total_loss=0.999,             accuracy=0.906\nepoch 29, step 250,             total_loss=1.052,             accuracy=0.844\nepoch 29, step 300,             total_loss=1.095,             accuracy=0.875\nepoch 29, step 350,             total_loss=1.148,             accuracy=0.812\nepoch 29, step 400,             total_loss=1.347,             accuracy=0.719\nepoch 29, step 450,             total_loss=1.238,             accuracy=0.906\nepoch 29, step 500,             total_loss=1.324,             accuracy=0.812\n\n--- Validation phase ---\nEpoch    29: reducing learning rate of group 0 to 3.8152e-04.\nepoch 29, val_loss=0.469\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65d8381103804ac4960bee2bd1c6a4d2"}},"metadata":{}},{"output_type":"stream","text":"epoch 30, step 0,             total_loss=1.049,             accuracy=0.875\nepoch 30, step 50,             total_loss=0.981,             accuracy=0.938\nepoch 30, step 100,             total_loss=1.232,             accuracy=0.844\nepoch 30, step 150,             total_loss=0.813,             accuracy=0.906\nepoch 30, step 200,             total_loss=1.061,             accuracy=0.875\nepoch 30, step 250,             total_loss=0.916,             accuracy=0.938\nepoch 30, step 300,             total_loss=0.731,             accuracy=1.000\nepoch 30, step 350,             total_loss=0.951,             accuracy=0.906\nepoch 30, step 400,             total_loss=1.536,             accuracy=0.750\nepoch 30, step 450,             total_loss=0.947,             accuracy=0.938\nepoch 30, step 500,             total_loss=0.961,             accuracy=0.938\n\n--- Validation phase ---\nEpoch    30: reducing learning rate of group 0 to 3.4337e-04.\nepoch 30, val_loss=0.466\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c073adb3ac94a698c42d561e2bdc564"}},"metadata":{}},{"output_type":"stream","text":"epoch 31, step 0,             total_loss=1.137,             accuracy=0.812\nepoch 31, step 50,             total_loss=1.191,             accuracy=0.812\nepoch 31, step 100,             total_loss=1.228,             accuracy=0.750\nepoch 31, step 150,             total_loss=1.292,             accuracy=0.781\nepoch 31, step 200,             total_loss=0.949,             accuracy=0.906\nepoch 31, step 250,             total_loss=0.865,             accuracy=0.938\nepoch 31, step 300,             total_loss=1.022,             accuracy=0.844\nepoch 31, step 350,             total_loss=0.843,             accuracy=0.969\nepoch 31, step 400,             total_loss=1.515,             accuracy=0.719\nepoch 31, step 450,             total_loss=1.299,             accuracy=0.812\nepoch 31, step 500,             total_loss=1.171,             accuracy=0.781\n\n--- Validation phase ---\nEpoch    31: reducing learning rate of group 0 to 3.0903e-04.\nepoch 31, val_loss=0.451\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e498d291b47458a8aa6aa32bd2e49bc"}},"metadata":{}},{"output_type":"stream","text":"epoch 32, step 0,             total_loss=1.184,             accuracy=0.812\nepoch 32, step 50,             total_loss=1.026,             accuracy=0.875\nepoch 32, step 100,             total_loss=1.235,             accuracy=0.812\nepoch 32, step 150,             total_loss=0.933,             accuracy=0.844\nepoch 32, step 200,             total_loss=1.038,             accuracy=0.875\nepoch 32, step 250,             total_loss=0.953,             accuracy=0.938\nepoch 32, step 300,             total_loss=1.050,             accuracy=0.875\nepoch 32, step 350,             total_loss=0.822,             accuracy=1.000\nepoch 32, step 400,             total_loss=1.725,             accuracy=0.688\nepoch 32, step 450,             total_loss=1.172,             accuracy=0.781\nepoch 32, step 500,             total_loss=1.097,             accuracy=0.844\n\n--- Validation phase ---\nEpoch    32: reducing learning rate of group 0 to 2.7813e-04.\nepoch 32, val_loss=0.446\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c77ccea92ce74d608148ca8b336b4d49"}},"metadata":{}},{"output_type":"stream","text":"epoch 33, step 0,             total_loss=1.165,             accuracy=0.844\nepoch 33, step 50,             total_loss=1.117,             accuracy=0.781\nepoch 33, step 100,             total_loss=1.362,             accuracy=0.812\nepoch 33, step 150,             total_loss=1.035,             accuracy=0.875\nepoch 33, step 200,             total_loss=1.046,             accuracy=0.875\nepoch 33, step 250,             total_loss=0.902,             accuracy=0.906\nepoch 33, step 300,             total_loss=1.109,             accuracy=0.750\nepoch 33, step 350,             total_loss=0.999,             accuracy=0.875\nepoch 33, step 400,             total_loss=1.335,             accuracy=0.750\nepoch 33, step 450,             total_loss=1.418,             accuracy=0.781\nepoch 33, step 500,             total_loss=0.905,             accuracy=0.938\n\n--- Validation phase ---\nEpoch    33: reducing learning rate of group 0 to 2.5032e-04.\nepoch 33, val_loss=0.444\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75eb44429e024138b5d7afc753ff1bbc"}},"metadata":{}},{"output_type":"stream","text":"epoch 34, step 0,             total_loss=1.036,             accuracy=0.906\nepoch 34, step 50,             total_loss=1.478,             accuracy=0.750\nepoch 34, step 100,             total_loss=1.364,             accuracy=0.750\nepoch 34, step 150,             total_loss=1.086,             accuracy=0.844\nepoch 34, step 200,             total_loss=0.845,             accuracy=0.938\nepoch 34, step 250,             total_loss=0.788,             accuracy=0.969\nepoch 34, step 300,             total_loss=0.970,             accuracy=0.875\nepoch 34, step 350,             total_loss=0.939,             accuracy=0.906\nepoch 34, step 400,             total_loss=1.381,             accuracy=0.812\nepoch 34, step 450,             total_loss=1.135,             accuracy=0.875\nepoch 34, step 500,             total_loss=0.800,             accuracy=0.969\n\n--- Validation phase ---\nEpoch    34: reducing learning rate of group 0 to 2.2528e-04.\nepoch 34, val_loss=0.424\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5260dadc3a97499abbbf9c363f6a977f"}},"metadata":{}},{"output_type":"stream","text":"epoch 35, step 0,             total_loss=1.154,             accuracy=0.781\nepoch 35, step 50,             total_loss=1.056,             accuracy=0.812\nepoch 35, step 100,             total_loss=1.190,             accuracy=0.812\nepoch 35, step 150,             total_loss=1.109,             accuracy=0.844\nepoch 35, step 200,             total_loss=0.867,             accuracy=0.938\nepoch 35, step 250,             total_loss=0.834,             accuracy=0.969\nepoch 35, step 300,             total_loss=1.026,             accuracy=0.812\nepoch 35, step 350,             total_loss=0.776,             accuracy=0.969\nepoch 35, step 400,             total_loss=1.130,             accuracy=0.812\nepoch 35, step 450,             total_loss=1.280,             accuracy=0.812\nepoch 35, step 500,             total_loss=0.884,             accuracy=0.938\n\n--- Validation phase ---\nEpoch    35: reducing learning rate of group 0 to 2.0276e-04.\nEpoch    35: reducing learning rate of group 0 to 1.8248e-04.\nepoch 35, val_loss=0.437\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc513b5a63924138b5849c06b3d092a8"}},"metadata":{}},{"output_type":"stream","text":"epoch 36, step 0,             total_loss=1.087,             accuracy=0.844\nepoch 36, step 50,             total_loss=0.914,             accuracy=0.938\nepoch 36, step 100,             total_loss=1.200,             accuracy=0.812\nepoch 36, step 150,             total_loss=0.792,             accuracy=0.938\nepoch 36, step 200,             total_loss=1.006,             accuracy=0.906\nepoch 36, step 250,             total_loss=0.862,             accuracy=0.906\nepoch 36, step 300,             total_loss=0.933,             accuracy=0.906\nepoch 36, step 350,             total_loss=1.012,             accuracy=0.875\nepoch 36, step 400,             total_loss=1.169,             accuracy=0.844\nepoch 36, step 450,             total_loss=1.241,             accuracy=0.875\nepoch 36, step 500,             total_loss=0.789,             accuracy=0.969\n\n--- Validation phase ---\nEpoch    36: reducing learning rate of group 0 to 1.6423e-04.\nepoch 36, val_loss=0.420\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b768037cd3e04546b30841f5882d974c"}},"metadata":{}},{"output_type":"stream","text":"epoch 37, step 0,             total_loss=1.060,             accuracy=0.812\nepoch 37, step 50,             total_loss=0.974,             accuracy=0.844\nepoch 37, step 100,             total_loss=1.132,             accuracy=0.906\nepoch 37, step 150,             total_loss=0.984,             accuracy=0.875\nepoch 37, step 200,             total_loss=0.917,             accuracy=0.875\nepoch 37, step 250,             total_loss=0.850,             accuracy=0.906\nepoch 37, step 300,             total_loss=1.056,             accuracy=0.875\nepoch 37, step 350,             total_loss=0.868,             accuracy=0.938\nepoch 37, step 400,             total_loss=1.223,             accuracy=0.812\nepoch 37, step 450,             total_loss=1.071,             accuracy=0.875\nepoch 37, step 500,             total_loss=1.013,             accuracy=0.875\n\n--- Validation phase ---\nEpoch    37: reducing learning rate of group 0 to 1.4781e-04.\nEpoch    37: reducing learning rate of group 0 to 1.3303e-04.\nepoch 37, val_loss=0.431\nEarly stopping\n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'writer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-c7a99beaeb8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finish all training !'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'writer' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"### Validation Phase"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\"\"\" \nIf you want load other pretrained model, please uncomment following two lines.\nTry to load your model and put parameters in neural network structure.\nOr you can recover a pretrained model including parameters and the arichitecture. \n\"\"\"\n# CKPT_PATH = 'model_best.ckpt' \n# model.load_state_dict(torch.load(CKPT_PATH)['state_dict'])\nmodel.eval()\nacc = 0\nfor i, (img_batch, label_batch) in enumerate(valid_loader):\n    output = model(img_batch.to(device))\n    _, predicted = torch.max(output.cpu().data, 1)\n    accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n    acc += accuracy\nprint('accuracy={}'.format(acc/len(valid_loader)))","execution_count":22,"outputs":[{"output_type":"stream","text":"accuracy=0.9087591171264648\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.save(model, 'whole_model.ckpt')","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"}},"nbformat":4,"nbformat_minor":4}