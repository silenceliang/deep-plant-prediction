{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "LABEL_DIR = 'label2.csv'\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, 'DaanForestPark')\n",
    "# IMAGE_DIR = os.path.join(DATA_DIR, '17category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 20\n",
    "ZIPSIZE = 4\n",
    "FILTER_NUMS = 8\n",
    "FILTER_NUMS2 = 16\n",
    "CHANNEL_NUMS = 3\n",
    "KERNEL_SIZE = 13\n",
    "STRIDE = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-2\n",
    "HEIGHT, WEIDTH = 1136, 640\n",
    "# 340 * 192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToPILImage() -> Resize() -> ToTensor()\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = (0.5, 0.5, 0.5), std = (0.5, 0.5, 0.5))\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DataSet and the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        _images, _labels = [], []\n",
    "        # total amount of dataset \n",
    "        _number = 0\n",
    "        # Reading the categorical file\n",
    "        label_df = pd.read_csv(label_dir)\n",
    "        \n",
    "        # Iterate all files including .jpg inages  \n",
    "        for subdir, dirs, files in tqdm(os.walk(image_dir)):\n",
    "            for filename in files:\n",
    "                corr_label = label_df[label_df['dirpath']==subdir[len(DATA_DIR)+1:]]['label'].values\n",
    "                if corr_label.size!= 0 and filename.endswith(('jpg')):\n",
    "                    _images.append(subdir + os.sep + filename)\n",
    "                    _labels.append(corr_label)\n",
    "                    _number+=1\n",
    "        \n",
    "        # Randomly arrange data pairs\n",
    "        mapIndexPosition = list(zip(_images, _labels))\n",
    "        random.shuffle(mapIndexPosition)\n",
    "        _images, _labels = zip(*mapIndexPosition)\n",
    "\n",
    "        self._image = iter(_images)\n",
    "        self._labels = iter(_labels)\n",
    "        self._number = _number\n",
    "        self._category = label_df['label'].nunique()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._number\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        img = next(self._image)\n",
    "        lab = next(self._labels)\n",
    "        \n",
    "        img = self._loadimage(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, lab\n",
    "     \n",
    "    def _categorical(self, label):\n",
    "        return np.arange(self._category) == label[:,None]\n",
    "    \n",
    "    def _loadimage(self, file):\n",
    "#         image = cv2.imread(file).reshape(HEIGHT, WEIDTH,CHANNEL_NUMS)\n",
    "        image = cv2.imread(file)\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    def _resizeimage(self, img, scale_percent=30):\n",
    "        width = int(img.shape[1] * scale_percent / 100)\n",
    "        height = int(img.shape[0] * scale_percent / 100)\n",
    "        dim = (width, height)\n",
    "        resized = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
    "        return resized\n",
    "    \n",
    "    def get_categorical_nums(self):\n",
    "        return self._category\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303ae43bb872488d85219a1d8fe9698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(IMAGE_DIR, LABEL_DIR, transform=transform)\n",
    "\n",
    "valid_size = .1\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=train_sampler, drop_last=True)\n",
    "valid_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=valid_sampler, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def init_weights(m):\n",
    "#     if type(m) == nn.Conv2d:\n",
    "#         nn.init.xavier_uniform(m.weight)\n",
    "#         m.bias.data.fill_(0.01)\n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.uniform_(m.weight)\n",
    "#         m.bias.data.fill_(0.01)   \n",
    "# class SimpleCNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, target):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         # Input size (3, 1136, 640)\n",
    "# #         self.imgzipper  = nn.AvgPool2d(kernel_size=ZIPSIZE)\n",
    "#         # Input size (3, 284, 160)\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=CHANNEL_NUMS,\n",
    "#                         out_channels=FILTER_NUMS,\n",
    "#                         kernel_size=KERNEL_SIZE,\n",
    "#                         stride=STRIDE,\n",
    "#                         padding=(KERNEL_SIZE-STRIDE)//2 # padding=(kernel_size-stride)/2 -> original size\n",
    "#                     ),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.ReLU(),\n",
    "#             # (8, 1136, 640)\n",
    "#             nn.MaxPool2d(kernel_size=KERNEL_SIZE)\n",
    "#             # (8, 87, 49)\n",
    "#             # zipper (8, 21, 12)\n",
    "#         ).apply(init_weights)\n",
    "        \n",
    "#         # (8, 87, 49)\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=FILTER_NUMS,\n",
    "#                         out_channels=FILTER_NUMS2,\n",
    "#                         kernel_size=KERNEL_SIZE,\n",
    "#                         stride=STRIDE,\n",
    "#                         padding=(KERNEL_SIZE-STRIDE)//2 # padding=(kernel_size-stride)/2 -> original size\n",
    "#                     ),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.ReLU(),\n",
    "#             # (16, 87, 49)\n",
    "#             nn.MaxPool2d(kernel_size=5)\n",
    "#             # (16, 6, 3)\n",
    "#         ).apply(init_weights)\n",
    "#         self.MLP = nn.Sequential(\n",
    "#             nn.Linear(128, 81),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(81, 81),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(81, target)\n",
    "#         ).apply(init_weights)\n",
    "#     def forward(self, x):\n",
    "#         x = self.imgzipper(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.MLP(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleCNN(train_dataset.get_categorical_nums()).to(device)\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 170, 96]           9,408\n",
      "       BatchNorm2d-2          [-1, 64, 170, 96]             128\n",
      "              ReLU-3          [-1, 64, 170, 96]               0\n",
      "         MaxPool2d-4           [-1, 64, 85, 48]               0\n",
      "            Conv2d-5           [-1, 64, 85, 48]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 85, 48]             128\n",
      "              ReLU-7           [-1, 64, 85, 48]               0\n",
      "            Conv2d-8           [-1, 64, 85, 48]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 85, 48]             128\n",
      "             ReLU-10           [-1, 64, 85, 48]               0\n",
      "       BasicBlock-11           [-1, 64, 85, 48]               0\n",
      "           Conv2d-12           [-1, 64, 85, 48]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 85, 48]             128\n",
      "             ReLU-14           [-1, 64, 85, 48]               0\n",
      "           Conv2d-15           [-1, 64, 85, 48]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 85, 48]             128\n",
      "             ReLU-17           [-1, 64, 85, 48]               0\n",
      "       BasicBlock-18           [-1, 64, 85, 48]               0\n",
      "           Conv2d-19          [-1, 128, 43, 24]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 43, 24]             256\n",
      "             ReLU-21          [-1, 128, 43, 24]               0\n",
      "           Conv2d-22          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 43, 24]             256\n",
      "           Conv2d-24          [-1, 128, 43, 24]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 43, 24]             256\n",
      "             ReLU-26          [-1, 128, 43, 24]               0\n",
      "       BasicBlock-27          [-1, 128, 43, 24]               0\n",
      "           Conv2d-28          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 43, 24]             256\n",
      "             ReLU-30          [-1, 128, 43, 24]               0\n",
      "           Conv2d-31          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 43, 24]             256\n",
      "             ReLU-33          [-1, 128, 43, 24]               0\n",
      "       BasicBlock-34          [-1, 128, 43, 24]               0\n",
      "           Conv2d-35          [-1, 256, 22, 12]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 22, 12]             512\n",
      "             ReLU-37          [-1, 256, 22, 12]               0\n",
      "           Conv2d-38          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 22, 12]             512\n",
      "           Conv2d-40          [-1, 256, 22, 12]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 22, 12]             512\n",
      "             ReLU-42          [-1, 256, 22, 12]               0\n",
      "       BasicBlock-43          [-1, 256, 22, 12]               0\n",
      "           Conv2d-44          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 22, 12]             512\n",
      "             ReLU-46          [-1, 256, 22, 12]               0\n",
      "           Conv2d-47          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 22, 12]             512\n",
      "             ReLU-49          [-1, 256, 22, 12]               0\n",
      "       BasicBlock-50          [-1, 256, 22, 12]               0\n",
      "           Conv2d-51           [-1, 512, 11, 6]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-53           [-1, 512, 11, 6]               0\n",
      "           Conv2d-54           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 11, 6]           1,024\n",
      "           Conv2d-56           [-1, 512, 11, 6]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-58           [-1, 512, 11, 6]               0\n",
      "       BasicBlock-59           [-1, 512, 11, 6]               0\n",
      "           Conv2d-60           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-62           [-1, 512, 11, 6]               0\n",
      "           Conv2d-63           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-65           [-1, 512, 11, 6]               0\n",
      "       BasicBlock-66           [-1, 512, 11, 6]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 85]          43,605\n",
      "================================================================\n",
      "Total params: 11,220,117\n",
      "Trainable params: 11,220,117\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.29\n",
      "Params size (MB): 42.80\n",
      "Estimated Total Size (MB): 125.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# channels, H, W\n",
    "model = model_ft.to(device=device)\n",
    "summary(model, input_size=(CHANNEL_NUMS, 340, 192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradient(optimizer, grad_clip):\n",
    "    \"\"\"\n",
    "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
    "\n",
    "    :param optimizer: optimizer with the gradients to be clipped\n",
    "    :param grad_clip: clip value\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group[\"params\"]:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "def save_checkpoint(state, filename='model.ckpt'):\n",
    "    torch.save(state, filename)\n",
    "    shutil.copyfile(filename, 'model_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b13cd571f24df4a6a55dd0821aa025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 0, loss=4.671567916870117, accuracy=0.03125\n",
      "epoch 1, step 20, loss=6.5467095375061035, accuracy=0.03125\n",
      "epoch 1, step 40, loss=5.381259441375732, accuracy=0.03125\n",
      "epoch 1, step 60, loss=5.342200756072998, accuracy=0.0625\n",
      "epoch 1, step 80, loss=4.601925373077393, accuracy=0.03125\n",
      "epoch 1, step 100, loss=3.9714481830596924, accuracy=0.0625\n",
      "epoch 1, step 120, loss=4.118907451629639, accuracy=0.0625\n",
      "epoch 1, step 140, loss=4.026341915130615, accuracy=0.03125\n",
      "epoch 1, step 160, loss=4.102416515350342, accuracy=0.09375\n",
      "epoch 1, step 180, loss=3.995544910430908, accuracy=0.125\n",
      "epoch 1, step 200, loss=3.7514302730560303, accuracy=0.0625\n",
      "epoch 1, step 220, loss=3.7040164470672607, accuracy=0.09375\n",
      "epoch 1, step 240, loss=3.688523530960083, accuracy=0.15625\n",
      "epoch 1, step 260, loss=3.9163589477539062, accuracy=0.09375\n",
      "epoch 1, step 280, loss=3.6367268562316895, accuracy=0.125\n",
      "epoch 1, step 300, loss=3.7971279621124268, accuracy=0.15625\n",
      "epoch 1, step 320, loss=3.50956130027771, accuracy=0.09375\n",
      "epoch 1, step 340, loss=3.8055357933044434, accuracy=0.15625\n",
      "epoch 1, step 360, loss=3.798224449157715, accuracy=0.0625\n",
      "epoch 1, step 380, loss=3.581139087677002, accuracy=0.125\n",
      "epoch 1, step 400, loss=3.2378225326538086, accuracy=0.1875\n",
      "epoch 1, step 420, loss=3.985837697982788, accuracy=0.0625\n",
      "epoch 1, step 440, loss=3.5876331329345703, accuracy=0.125\n",
      "epoch 1, step 460, loss=3.5250439643859863, accuracy=0.125\n",
      "epoch 1, step 480, loss=3.157834768295288, accuracy=0.21875\n",
      "epoch 1, step 500, loss=3.0566022396087646, accuracy=0.25\n",
      "epoch 1, step 520, loss=3.4257969856262207, accuracy=0.09375\n",
      "epoch 1, step 540, loss=3.5131869316101074, accuracy=0.09375\n",
      "epoch 1, step 560, loss=3.497079610824585, accuracy=0.1875\n",
      "epoch 1, step 580, loss=3.34657621383667, accuracy=0.0625\n",
      "epoch 1, step 600, loss=3.389557361602783, accuracy=0.125\n",
      "\n",
      "epoch 1, val_loss=3.5881832732873806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51a52025f0e4727ae3c5b826f9f52a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 0, loss=3.3742737770080566, accuracy=0.125\n",
      "epoch 2, step 20, loss=3.097829580307007, accuracy=0.0625\n",
      "epoch 2, step 40, loss=3.063203811645508, accuracy=0.1875\n",
      "epoch 2, step 60, loss=2.8077919483184814, accuracy=0.21875\n",
      "epoch 2, step 80, loss=3.7494421005249023, accuracy=0.0625\n",
      "epoch 2, step 100, loss=3.0976271629333496, accuracy=0.21875\n",
      "epoch 2, step 120, loss=3.4226791858673096, accuracy=0.09375\n",
      "epoch 2, step 140, loss=3.2383439540863037, accuracy=0.09375\n",
      "epoch 2, step 160, loss=3.17246675491333, accuracy=0.125\n",
      "epoch 2, step 180, loss=3.6158957481384277, accuracy=0.15625\n",
      "epoch 2, step 200, loss=3.100374698638916, accuracy=0.15625\n",
      "epoch 2, step 220, loss=3.1065409183502197, accuracy=0.25\n",
      "epoch 2, step 240, loss=3.112060308456421, accuracy=0.21875\n",
      "epoch 2, step 260, loss=3.355567455291748, accuracy=0.15625\n",
      "epoch 2, step 280, loss=2.8525829315185547, accuracy=0.21875\n",
      "epoch 2, step 300, loss=2.863534688949585, accuracy=0.3125\n",
      "epoch 2, step 320, loss=2.798459768295288, accuracy=0.21875\n",
      "epoch 2, step 340, loss=2.88431453704834, accuracy=0.21875\n",
      "epoch 2, step 360, loss=3.4509503841400146, accuracy=0.15625\n",
      "epoch 2, step 380, loss=2.7091236114501953, accuracy=0.40625\n",
      "epoch 2, step 400, loss=2.718400239944458, accuracy=0.25\n",
      "epoch 2, step 420, loss=2.8339250087738037, accuracy=0.125\n",
      "epoch 2, step 440, loss=3.008657217025757, accuracy=0.15625\n",
      "epoch 2, step 460, loss=2.4987127780914307, accuracy=0.28125\n",
      "epoch 2, step 480, loss=2.532787799835205, accuracy=0.25\n",
      "epoch 2, step 500, loss=2.5113167762756348, accuracy=0.21875\n",
      "epoch 2, step 520, loss=2.6587281227111816, accuracy=0.28125\n",
      "epoch 2, step 540, loss=2.850437641143799, accuracy=0.125\n",
      "epoch 2, step 560, loss=2.927478551864624, accuracy=0.28125\n",
      "epoch 2, step 580, loss=3.058364152908325, accuracy=0.125\n",
      "epoch 2, step 600, loss=2.7162773609161377, accuracy=0.3125\n",
      "\n",
      "epoch 2, val_loss=2.88754897257861\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7ecd659aae4998a71c07ae4b1515a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 0, loss=2.579862117767334, accuracy=0.25\n",
      "epoch 3, step 20, loss=2.6845734119415283, accuracy=0.1875\n",
      "epoch 3, step 40, loss=2.589587688446045, accuracy=0.28125\n",
      "epoch 3, step 60, loss=2.313965320587158, accuracy=0.3125\n",
      "epoch 3, step 80, loss=3.583925247192383, accuracy=0.09375\n",
      "epoch 3, step 100, loss=2.5829851627349854, accuracy=0.1875\n",
      "epoch 3, step 120, loss=2.9595861434936523, accuracy=0.28125\n",
      "epoch 3, step 140, loss=2.672018051147461, accuracy=0.21875\n",
      "epoch 3, step 160, loss=2.6360838413238525, accuracy=0.40625\n",
      "epoch 3, step 180, loss=3.342761993408203, accuracy=0.125\n",
      "epoch 3, step 200, loss=2.5084497928619385, accuracy=0.3125\n",
      "epoch 3, step 220, loss=2.72106671333313, accuracy=0.375\n",
      "epoch 3, step 240, loss=2.7086031436920166, accuracy=0.40625\n",
      "epoch 3, step 260, loss=2.5347771644592285, accuracy=0.34375\n",
      "epoch 3, step 280, loss=2.2406883239746094, accuracy=0.40625\n",
      "epoch 3, step 300, loss=2.691155195236206, accuracy=0.375\n",
      "epoch 3, step 320, loss=2.1123046875, accuracy=0.28125\n",
      "epoch 3, step 340, loss=2.655824899673462, accuracy=0.25\n",
      "epoch 3, step 360, loss=3.0649149417877197, accuracy=0.28125\n",
      "epoch 3, step 380, loss=1.9349381923675537, accuracy=0.5\n",
      "epoch 3, step 400, loss=2.1735973358154297, accuracy=0.375\n",
      "epoch 3, step 420, loss=2.295910596847534, accuracy=0.25\n",
      "epoch 3, step 440, loss=2.4570906162261963, accuracy=0.28125\n",
      "epoch 3, step 460, loss=2.0929746627807617, accuracy=0.4375\n",
      "epoch 3, step 480, loss=2.0105347633361816, accuracy=0.5\n",
      "epoch 3, step 500, loss=2.0857951641082764, accuracy=0.34375\n",
      "epoch 3, step 520, loss=2.110935926437378, accuracy=0.3125\n",
      "epoch 3, step 540, loss=2.2452712059020996, accuracy=0.375\n",
      "epoch 3, step 560, loss=2.286245346069336, accuracy=0.375\n",
      "epoch 3, step 580, loss=2.2324719429016113, accuracy=0.28125\n",
      "epoch 3, step 600, loss=2.1991827487945557, accuracy=0.34375\n",
      "\n",
      "epoch 3, val_loss=2.2715633704381832\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d38834f2fc49edb212df2752fce8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 0, loss=2.147911310195923, accuracy=0.3125\n",
      "epoch 4, step 20, loss=2.1254758834838867, accuracy=0.28125\n",
      "epoch 4, step 40, loss=1.6722394227981567, accuracy=0.53125\n",
      "epoch 4, step 60, loss=1.701303482055664, accuracy=0.6875\n",
      "epoch 4, step 80, loss=2.5288493633270264, accuracy=0.40625\n",
      "epoch 4, step 100, loss=2.0208992958068848, accuracy=0.375\n",
      "epoch 4, step 120, loss=2.347501516342163, accuracy=0.25\n",
      "epoch 4, step 140, loss=1.8022918701171875, accuracy=0.34375\n",
      "epoch 4, step 160, loss=2.2203285694122314, accuracy=0.375\n",
      "epoch 4, step 180, loss=2.680549383163452, accuracy=0.3125\n",
      "epoch 4, step 200, loss=2.2338039875030518, accuracy=0.4375\n",
      "epoch 4, step 220, loss=2.0390448570251465, accuracy=0.28125\n",
      "epoch 4, step 240, loss=1.8643133640289307, accuracy=0.53125\n",
      "epoch 4, step 260, loss=2.1024093627929688, accuracy=0.40625\n",
      "epoch 4, step 280, loss=1.5703718662261963, accuracy=0.4375\n",
      "epoch 4, step 300, loss=2.194206476211548, accuracy=0.40625\n",
      "epoch 4, step 320, loss=1.7361360788345337, accuracy=0.375\n",
      "epoch 4, step 340, loss=1.8356051445007324, accuracy=0.5\n",
      "epoch 4, step 360, loss=2.6523945331573486, accuracy=0.28125\n",
      "epoch 4, step 380, loss=1.5956486463546753, accuracy=0.5625\n",
      "epoch 4, step 400, loss=1.6749944686889648, accuracy=0.4375\n",
      "epoch 4, step 420, loss=2.013240098953247, accuracy=0.34375\n",
      "epoch 4, step 440, loss=1.9450253248214722, accuracy=0.28125\n",
      "epoch 4, step 460, loss=1.6571104526519775, accuracy=0.46875\n",
      "epoch 4, step 480, loss=1.9386284351348877, accuracy=0.46875\n",
      "epoch 4, step 500, loss=1.3889297246932983, accuracy=0.53125\n",
      "epoch 4, step 520, loss=1.9128978252410889, accuracy=0.40625\n",
      "epoch 4, step 540, loss=1.864879846572876, accuracy=0.3125\n",
      "epoch 4, step 560, loss=2.110203742980957, accuracy=0.53125\n",
      "epoch 4, step 580, loss=1.6876580715179443, accuracy=0.5625\n",
      "epoch 4, step 600, loss=2.019483804702759, accuracy=0.40625\n",
      "\n",
      "epoch 4, val_loss=2.080105243360295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6fe53926714076a05b23fd8e366c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 0, loss=1.878986120223999, accuracy=0.375\n",
      "epoch 5, step 20, loss=1.9198325872421265, accuracy=0.53125\n",
      "epoch 5, step 40, loss=1.5494792461395264, accuracy=0.625\n",
      "epoch 5, step 60, loss=1.2075430154800415, accuracy=0.65625\n",
      "epoch 5, step 80, loss=2.4435997009277344, accuracy=0.5\n",
      "epoch 5, step 100, loss=1.6132625341415405, accuracy=0.5625\n",
      "epoch 5, step 120, loss=2.4430055618286133, accuracy=0.3125\n",
      "epoch 5, step 140, loss=1.6947693824768066, accuracy=0.375\n",
      "epoch 5, step 160, loss=1.7711858749389648, accuracy=0.40625\n",
      "epoch 5, step 180, loss=2.2767140865325928, accuracy=0.3125\n",
      "epoch 5, step 200, loss=2.2410836219787598, accuracy=0.4375\n",
      "epoch 5, step 220, loss=1.834011435508728, accuracy=0.46875\n",
      "epoch 5, step 240, loss=1.6932880878448486, accuracy=0.5625\n",
      "epoch 5, step 260, loss=1.8983572721481323, accuracy=0.40625\n",
      "epoch 5, step 280, loss=1.542979121208191, accuracy=0.53125\n",
      "epoch 5, step 300, loss=1.6023783683776855, accuracy=0.5625\n",
      "epoch 5, step 320, loss=1.9003419876098633, accuracy=0.4375\n",
      "epoch 5, step 340, loss=1.644651174545288, accuracy=0.59375\n",
      "epoch 5, step 360, loss=1.8349698781967163, accuracy=0.5\n",
      "epoch 5, step 380, loss=1.3319581747055054, accuracy=0.625\n",
      "epoch 5, step 400, loss=1.3705247640609741, accuracy=0.5\n",
      "epoch 5, step 420, loss=1.7038519382476807, accuracy=0.4375\n",
      "epoch 5, step 440, loss=1.5131301879882812, accuracy=0.59375\n",
      "epoch 5, step 460, loss=1.4878182411193848, accuracy=0.5\n",
      "epoch 5, step 480, loss=1.488526463508606, accuracy=0.5625\n",
      "epoch 5, step 500, loss=1.3193140029907227, accuracy=0.53125\n",
      "epoch 5, step 520, loss=1.4396228790283203, accuracy=0.5625\n",
      "epoch 5, step 540, loss=1.8205540180206299, accuracy=0.5625\n",
      "epoch 5, step 560, loss=1.7915970087051392, accuracy=0.5625\n",
      "epoch 5, step 580, loss=1.7118314504623413, accuracy=0.46875\n",
      "epoch 5, step 600, loss=1.6674306392669678, accuracy=0.46875\n",
      "\n",
      "epoch 5, val_loss=1.9158956636400784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540a1296681545f793de7843e9102e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, step 0, loss=1.4143675565719604, accuracy=0.53125\n",
      "epoch 6, step 20, loss=1.452266812324524, accuracy=0.71875\n",
      "epoch 6, step 40, loss=1.6065306663513184, accuracy=0.6875\n",
      "epoch 6, step 60, loss=1.2399283647537231, accuracy=0.625\n",
      "epoch 6, step 80, loss=1.6992249488830566, accuracy=0.5625\n",
      "epoch 6, step 100, loss=1.5151106119155884, accuracy=0.5625\n",
      "epoch 6, step 120, loss=2.130459785461426, accuracy=0.4375\n",
      "epoch 6, step 140, loss=1.4047186374664307, accuracy=0.53125\n",
      "epoch 6, step 160, loss=1.4300258159637451, accuracy=0.59375\n",
      "epoch 6, step 180, loss=1.8323861360549927, accuracy=0.4375\n",
      "epoch 6, step 200, loss=1.942037582397461, accuracy=0.4375\n",
      "epoch 6, step 220, loss=1.4173675775527954, accuracy=0.625\n",
      "epoch 6, step 240, loss=1.4227826595306396, accuracy=0.625\n",
      "epoch 6, step 260, loss=1.4679360389709473, accuracy=0.59375\n",
      "epoch 6, step 280, loss=1.1961770057678223, accuracy=0.625\n",
      "epoch 6, step 300, loss=1.4692515134811401, accuracy=0.625\n",
      "epoch 6, step 320, loss=1.2574423551559448, accuracy=0.53125\n",
      "epoch 6, step 340, loss=1.2561912536621094, accuracy=0.6875\n",
      "epoch 6, step 360, loss=1.4463244676589966, accuracy=0.59375\n",
      "epoch 6, step 380, loss=0.7722911834716797, accuracy=0.71875\n",
      "epoch 6, step 400, loss=0.9334908723831177, accuracy=0.71875\n",
      "epoch 6, step 420, loss=1.682004690170288, accuracy=0.5625\n",
      "epoch 6, step 440, loss=1.2320277690887451, accuracy=0.625\n",
      "epoch 6, step 460, loss=1.1758739948272705, accuracy=0.625\n",
      "epoch 6, step 480, loss=1.0441335439682007, accuracy=0.65625\n",
      "epoch 6, step 500, loss=0.9128986597061157, accuracy=0.71875\n",
      "epoch 6, step 520, loss=1.0666191577911377, accuracy=0.65625\n",
      "epoch 6, step 540, loss=1.2210627794265747, accuracy=0.625\n",
      "epoch 6, step 560, loss=1.2985191345214844, accuracy=0.625\n",
      "epoch 6, step 580, loss=0.9731853008270264, accuracy=0.71875\n",
      "epoch 6, step 600, loss=1.5054430961608887, accuracy=0.65625\n",
      "\n",
      "epoch 6, val_loss=1.4470455488737892\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44f04d585194bee8b2ec7ed8cbf17b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, step 0, loss=1.3905975818634033, accuracy=0.5625\n",
      "epoch 7, step 20, loss=0.9200831055641174, accuracy=0.78125\n",
      "epoch 7, step 40, loss=1.3943487405776978, accuracy=0.59375\n",
      "epoch 7, step 60, loss=1.0035028457641602, accuracy=0.71875\n",
      "epoch 7, step 80, loss=1.9390852451324463, accuracy=0.5\n",
      "epoch 7, step 100, loss=1.0279790163040161, accuracy=0.6875\n",
      "epoch 7, step 120, loss=1.7618608474731445, accuracy=0.34375\n",
      "epoch 7, step 140, loss=1.0907901525497437, accuracy=0.75\n",
      "epoch 7, step 160, loss=1.2691212892532349, accuracy=0.59375\n",
      "epoch 7, step 180, loss=1.5272905826568604, accuracy=0.53125\n",
      "epoch 7, step 200, loss=1.7150086164474487, accuracy=0.5\n",
      "epoch 7, step 220, loss=1.5620183944702148, accuracy=0.625\n",
      "epoch 7, step 240, loss=1.3125243186950684, accuracy=0.65625\n",
      "epoch 7, step 260, loss=1.3492952585220337, accuracy=0.65625\n",
      "epoch 7, step 280, loss=0.869901716709137, accuracy=0.71875\n",
      "epoch 7, step 300, loss=0.8641990423202515, accuracy=0.75\n",
      "epoch 7, step 320, loss=1.0220186710357666, accuracy=0.71875\n",
      "epoch 7, step 340, loss=1.2713956832885742, accuracy=0.59375\n",
      "epoch 7, step 360, loss=1.6345199346542358, accuracy=0.5625\n",
      "epoch 7, step 380, loss=0.9624684453010559, accuracy=0.71875\n",
      "epoch 7, step 400, loss=0.8820300698280334, accuracy=0.78125\n",
      "epoch 7, step 420, loss=0.9950038194656372, accuracy=0.71875\n",
      "epoch 7, step 440, loss=1.1775381565093994, accuracy=0.65625\n",
      "epoch 7, step 460, loss=1.0352228879928589, accuracy=0.5625\n",
      "epoch 7, step 480, loss=0.941635012626648, accuracy=0.78125\n",
      "epoch 7, step 500, loss=0.7968561053276062, accuracy=0.6875\n",
      "epoch 7, step 520, loss=1.3477312326431274, accuracy=0.6875\n",
      "epoch 7, step 540, loss=1.128161907196045, accuracy=0.78125\n",
      "epoch 7, step 560, loss=1.1449798345565796, accuracy=0.6875\n",
      "epoch 7, step 580, loss=0.923631489276886, accuracy=0.65625\n",
      "epoch 7, step 600, loss=1.2908620834350586, accuracy=0.75\n",
      "\n",
      "epoch 7, val_loss=1.3933409364784466\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd1efb4950249a38eb11449cfefb86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 0, loss=0.9910120964050293, accuracy=0.65625\n",
      "epoch 8, step 20, loss=1.4238473176956177, accuracy=0.625\n",
      "epoch 8, step 40, loss=1.0123062133789062, accuracy=0.625\n",
      "epoch 8, step 60, loss=0.9814603328704834, accuracy=0.75\n",
      "epoch 8, step 80, loss=1.2214009761810303, accuracy=0.59375\n",
      "epoch 8, step 100, loss=1.015940546989441, accuracy=0.625\n",
      "epoch 8, step 120, loss=1.0569865703582764, accuracy=0.6875\n",
      "epoch 8, step 140, loss=1.2031550407409668, accuracy=0.71875\n",
      "epoch 8, step 160, loss=1.2540826797485352, accuracy=0.6875\n",
      "epoch 8, step 180, loss=1.59602689743042, accuracy=0.375\n",
      "epoch 8, step 200, loss=1.44540536403656, accuracy=0.59375\n",
      "epoch 8, step 220, loss=0.9929584264755249, accuracy=0.59375\n",
      "epoch 8, step 240, loss=1.2782355546951294, accuracy=0.625\n",
      "epoch 8, step 260, loss=1.065795660018921, accuracy=0.71875\n",
      "epoch 8, step 280, loss=0.4706387519836426, accuracy=0.84375\n",
      "epoch 8, step 300, loss=0.6425600051879883, accuracy=0.78125\n",
      "epoch 8, step 320, loss=0.9390038251876831, accuracy=0.6875\n",
      "epoch 8, step 340, loss=0.7402323484420776, accuracy=0.78125\n",
      "epoch 8, step 360, loss=1.6748385429382324, accuracy=0.5625\n",
      "epoch 8, step 380, loss=0.5230129957199097, accuracy=0.8125\n",
      "epoch 8, step 400, loss=0.6469694972038269, accuracy=0.78125\n",
      "epoch 8, step 420, loss=1.0018342733383179, accuracy=0.71875\n",
      "epoch 8, step 440, loss=0.8857588768005371, accuracy=0.75\n",
      "epoch 8, step 460, loss=1.0520573854446411, accuracy=0.6875\n",
      "epoch 8, step 480, loss=0.6663035154342651, accuracy=0.875\n",
      "epoch 8, step 500, loss=0.8379363417625427, accuracy=0.71875\n",
      "epoch 8, step 520, loss=0.4357989728450775, accuracy=0.875\n",
      "epoch 8, step 540, loss=0.8362761735916138, accuracy=0.78125\n",
      "epoch 8, step 560, loss=1.0817888975143433, accuracy=0.71875\n",
      "epoch 8, step 580, loss=0.8796874284744263, accuracy=0.78125\n",
      "epoch 8, step 600, loss=1.1910330057144165, accuracy=0.71875\n",
      "\n",
      "epoch 8, val_loss=1.0296705479131025\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db14a884b404315a29a86b4cf57d90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, step 0, loss=0.8609794974327087, accuracy=0.71875\n",
      "epoch 9, step 20, loss=0.8460136651992798, accuracy=0.75\n",
      "epoch 9, step 40, loss=1.2633569240570068, accuracy=0.65625\n",
      "epoch 9, step 60, loss=0.8856645822525024, accuracy=0.84375\n",
      "epoch 9, step 80, loss=1.5712525844573975, accuracy=0.5625\n",
      "epoch 9, step 100, loss=1.183443546295166, accuracy=0.625\n",
      "epoch 9, step 120, loss=0.8830428123474121, accuracy=0.75\n",
      "epoch 9, step 140, loss=1.2420364618301392, accuracy=0.625\n",
      "epoch 9, step 160, loss=0.7978774309158325, accuracy=0.8125\n",
      "epoch 9, step 180, loss=1.0106369256973267, accuracy=0.625\n",
      "epoch 9, step 200, loss=0.9383394122123718, accuracy=0.65625\n",
      "epoch 9, step 220, loss=1.3423166275024414, accuracy=0.65625\n",
      "epoch 9, step 240, loss=1.00179123878479, accuracy=0.71875\n",
      "epoch 9, step 260, loss=1.3496997356414795, accuracy=0.59375\n",
      "epoch 9, step 280, loss=0.6681790351867676, accuracy=0.78125\n",
      "epoch 9, step 300, loss=0.8995953798294067, accuracy=0.75\n",
      "epoch 9, step 320, loss=0.7750880122184753, accuracy=0.75\n",
      "epoch 9, step 340, loss=0.6874358654022217, accuracy=0.78125\n",
      "epoch 9, step 360, loss=1.0147868394851685, accuracy=0.65625\n",
      "epoch 9, step 380, loss=0.35575437545776367, accuracy=0.9375\n",
      "epoch 9, step 400, loss=0.8104750514030457, accuracy=0.71875\n",
      "epoch 9, step 420, loss=1.0538949966430664, accuracy=0.71875\n",
      "epoch 9, step 440, loss=0.855306088924408, accuracy=0.5625\n",
      "epoch 9, step 460, loss=1.2299246788024902, accuracy=0.71875\n",
      "epoch 9, step 480, loss=0.4864136278629303, accuracy=0.875\n",
      "epoch 9, step 500, loss=0.9631363153457642, accuracy=0.71875\n",
      "epoch 9, step 520, loss=0.9812251329421997, accuracy=0.84375\n",
      "epoch 9, step 540, loss=0.88929682970047, accuracy=0.65625\n",
      "epoch 9, step 560, loss=1.2268540859222412, accuracy=0.6875\n",
      "epoch 9, step 580, loss=0.667656421661377, accuracy=0.71875\n",
      "epoch 9, step 600, loss=1.1371651887893677, accuracy=0.71875\n",
      "\n",
      "epoch 9, val_loss=0.9238337602685479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1df01fb2d94c71b2165a9bade0fdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, step 0, loss=0.6417156457901001, accuracy=0.78125\n",
      "epoch 10, step 20, loss=0.9771443009376526, accuracy=0.71875\n",
      "epoch 10, step 40, loss=0.9411560893058777, accuracy=0.65625\n",
      "epoch 10, step 60, loss=0.6277148723602295, accuracy=0.71875\n",
      "epoch 10, step 80, loss=0.9328272938728333, accuracy=0.65625\n",
      "epoch 10, step 100, loss=0.527763843536377, accuracy=0.8125\n",
      "epoch 10, step 120, loss=0.862009584903717, accuracy=0.78125\n",
      "epoch 10, step 140, loss=0.9952446818351746, accuracy=0.65625\n",
      "epoch 10, step 160, loss=1.2737388610839844, accuracy=0.71875\n",
      "epoch 10, step 180, loss=0.812660813331604, accuracy=0.65625\n",
      "epoch 10, step 200, loss=1.1284786462783813, accuracy=0.75\n",
      "epoch 10, step 220, loss=1.151834487915039, accuracy=0.59375\n",
      "epoch 10, step 240, loss=0.8821616172790527, accuracy=0.6875\n",
      "epoch 10, step 260, loss=1.1319342851638794, accuracy=0.71875\n",
      "epoch 10, step 280, loss=0.42669951915740967, accuracy=0.875\n",
      "epoch 10, step 300, loss=0.6595611572265625, accuracy=0.8125\n",
      "epoch 10, step 320, loss=0.526819109916687, accuracy=0.84375\n",
      "epoch 10, step 340, loss=0.5745799541473389, accuracy=0.84375\n",
      "epoch 10, step 360, loss=0.7075672745704651, accuracy=0.75\n",
      "epoch 10, step 380, loss=0.3656078279018402, accuracy=0.9375\n",
      "epoch 10, step 400, loss=0.33068859577178955, accuracy=0.90625\n",
      "epoch 10, step 420, loss=0.5678573846817017, accuracy=0.84375\n",
      "epoch 10, step 440, loss=0.7831747531890869, accuracy=0.78125\n",
      "epoch 10, step 460, loss=0.4810270369052887, accuracy=0.78125\n",
      "epoch 10, step 480, loss=0.6154243350028992, accuracy=0.8125\n",
      "epoch 10, step 500, loss=0.6651595830917358, accuracy=0.75\n",
      "epoch 10, step 520, loss=0.8333964943885803, accuracy=0.6875\n",
      "epoch 10, step 540, loss=0.5010561943054199, accuracy=0.875\n",
      "epoch 10, step 560, loss=0.8916745185852051, accuracy=0.75\n",
      "epoch 10, step 580, loss=0.4612202048301697, accuracy=0.8125\n",
      "epoch 10, step 600, loss=1.1134626865386963, accuracy=0.71875\n",
      "\n",
      "epoch 10, val_loss=0.760128470028148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d648f830104bd2bfebac9c324cebfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, step 0, loss=0.8188281059265137, accuracy=0.8125\n",
      "epoch 11, step 20, loss=1.1006977558135986, accuracy=0.625\n",
      "epoch 11, step 40, loss=0.7519148588180542, accuracy=0.71875\n",
      "epoch 11, step 60, loss=0.5427334308624268, accuracy=0.84375\n",
      "epoch 11, step 80, loss=0.5198497772216797, accuracy=0.84375\n",
      "epoch 11, step 100, loss=0.46386831998825073, accuracy=0.8125\n",
      "epoch 11, step 120, loss=1.3164974451065063, accuracy=0.46875\n",
      "epoch 11, step 140, loss=0.9705235958099365, accuracy=0.78125\n",
      "epoch 11, step 160, loss=0.5924906730651855, accuracy=0.84375\n",
      "epoch 11, step 180, loss=0.932207465171814, accuracy=0.71875\n",
      "epoch 11, step 200, loss=1.1032992601394653, accuracy=0.6875\n",
      "epoch 11, step 220, loss=0.8325086832046509, accuracy=0.78125\n",
      "epoch 11, step 240, loss=0.7403455376625061, accuracy=0.78125\n",
      "epoch 11, step 260, loss=0.8395848274230957, accuracy=0.71875\n",
      "epoch 11, step 280, loss=0.8282145261764526, accuracy=0.78125\n",
      "epoch 11, step 300, loss=0.38563960790634155, accuracy=0.875\n",
      "epoch 11, step 320, loss=0.43876126408576965, accuracy=0.9375\n",
      "epoch 11, step 340, loss=0.21064960956573486, accuracy=0.96875\n",
      "epoch 11, step 360, loss=0.8680573105812073, accuracy=0.71875\n",
      "epoch 11, step 380, loss=0.33221960067749023, accuracy=0.90625\n",
      "epoch 11, step 400, loss=0.6514031887054443, accuracy=0.78125\n",
      "epoch 11, step 420, loss=0.658547043800354, accuracy=0.8125\n",
      "epoch 11, step 440, loss=0.5602707862854004, accuracy=0.75\n",
      "epoch 11, step 460, loss=0.8699954748153687, accuracy=0.8125\n",
      "epoch 11, step 480, loss=0.5581803917884827, accuracy=0.8125\n",
      "epoch 11, step 500, loss=0.4816114902496338, accuracy=0.875\n",
      "epoch 11, step 520, loss=0.5043487548828125, accuracy=0.8125\n",
      "epoch 11, step 540, loss=0.47445961833000183, accuracy=0.84375\n",
      "epoch 11, step 560, loss=0.9924778342247009, accuracy=0.75\n",
      "epoch 11, step 580, loss=0.551930844783783, accuracy=0.8125\n",
      "epoch 11, step 600, loss=0.7426444292068481, accuracy=0.78125\n",
      "\n",
      "epoch 11, val_loss=0.7588656641104642\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c98e148f83f447389d2b5b5a3b6340c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, step 0, loss=0.726274847984314, accuracy=0.78125\n",
      "epoch 12, step 20, loss=0.7743198871612549, accuracy=0.75\n",
      "epoch 12, step 40, loss=0.42054471373558044, accuracy=0.875\n",
      "epoch 12, step 60, loss=0.5211969614028931, accuracy=0.84375\n",
      "epoch 12, step 80, loss=0.4188309907913208, accuracy=0.875\n",
      "epoch 12, step 100, loss=0.503167986869812, accuracy=0.78125\n",
      "epoch 12, step 120, loss=0.6776552200317383, accuracy=0.75\n",
      "epoch 12, step 140, loss=0.6904396414756775, accuracy=0.8125\n",
      "epoch 12, step 160, loss=0.4916115403175354, accuracy=0.875\n",
      "epoch 12, step 180, loss=0.6215370297431946, accuracy=0.75\n",
      "epoch 12, step 200, loss=1.2064335346221924, accuracy=0.625\n",
      "epoch 12, step 220, loss=0.46538108587265015, accuracy=0.875\n",
      "epoch 12, step 240, loss=0.7371988892555237, accuracy=0.78125\n",
      "epoch 12, step 260, loss=0.8843119144439697, accuracy=0.8125\n",
      "epoch 12, step 280, loss=0.5459361672401428, accuracy=0.84375\n",
      "epoch 12, step 300, loss=0.7316473722457886, accuracy=0.78125\n",
      "epoch 12, step 320, loss=1.0310301780700684, accuracy=0.71875\n",
      "epoch 12, step 340, loss=0.43017035722732544, accuracy=0.90625\n",
      "epoch 12, step 360, loss=1.1193675994873047, accuracy=0.6875\n",
      "epoch 12, step 380, loss=0.39944449067115784, accuracy=0.96875\n",
      "epoch 12, step 400, loss=0.33266523480415344, accuracy=0.84375\n",
      "epoch 12, step 420, loss=0.8238627910614014, accuracy=0.78125\n",
      "epoch 12, step 440, loss=0.26663514971733093, accuracy=0.90625\n",
      "epoch 12, step 460, loss=0.45635297894477844, accuracy=0.78125\n",
      "epoch 12, step 480, loss=0.49863219261169434, accuracy=0.84375\n",
      "epoch 12, step 500, loss=0.4944988191127777, accuracy=0.8125\n",
      "epoch 12, step 520, loss=0.490451455116272, accuracy=0.8125\n",
      "epoch 12, step 540, loss=0.6841257810592651, accuracy=0.8125\n",
      "epoch 12, step 560, loss=0.9293311834335327, accuracy=0.6875\n",
      "epoch 12, step 580, loss=0.6031580567359924, accuracy=0.90625\n",
      "epoch 12, step 600, loss=0.521729588508606, accuracy=0.84375\n",
      "\n",
      "epoch 12, val_loss=0.5450792619410683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44efda657f9740a7a491e9f47fdb1bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, step 0, loss=0.29041939973831177, accuracy=0.90625\n",
      "epoch 13, step 20, loss=0.9072789549827576, accuracy=0.84375\n",
      "epoch 13, step 40, loss=0.5607641935348511, accuracy=0.84375\n",
      "epoch 13, step 60, loss=0.3788691759109497, accuracy=0.875\n",
      "epoch 13, step 80, loss=0.3634062111377716, accuracy=0.9375\n",
      "epoch 13, step 100, loss=0.3827592134475708, accuracy=0.875\n",
      "epoch 13, step 120, loss=0.9552939534187317, accuracy=0.71875\n",
      "epoch 13, step 140, loss=0.5062313079833984, accuracy=0.84375\n",
      "epoch 13, step 160, loss=0.6559087038040161, accuracy=0.75\n",
      "epoch 13, step 180, loss=0.5442779064178467, accuracy=0.78125\n",
      "epoch 13, step 200, loss=0.3603441119194031, accuracy=0.84375\n",
      "epoch 13, step 220, loss=0.44518256187438965, accuracy=0.875\n",
      "epoch 13, step 240, loss=0.6436267495155334, accuracy=0.8125\n",
      "epoch 13, step 260, loss=0.8646172881126404, accuracy=0.71875\n",
      "epoch 13, step 280, loss=0.28785213828086853, accuracy=0.9375\n",
      "epoch 13, step 300, loss=0.2279684990644455, accuracy=0.9375\n",
      "epoch 13, step 320, loss=0.4671229124069214, accuracy=0.84375\n",
      "epoch 13, step 340, loss=0.2597012221813202, accuracy=0.90625\n",
      "epoch 13, step 360, loss=0.7909858226776123, accuracy=0.71875\n",
      "epoch 13, step 380, loss=0.23023046553134918, accuracy=0.9375\n",
      "epoch 13, step 400, loss=0.45297980308532715, accuracy=0.875\n",
      "epoch 13, step 420, loss=0.4730668365955353, accuracy=0.9375\n",
      "epoch 13, step 440, loss=0.47201642394065857, accuracy=0.78125\n",
      "epoch 13, step 460, loss=0.19819435477256775, accuracy=0.90625\n",
      "epoch 13, step 480, loss=0.3934403657913208, accuracy=0.9375\n",
      "epoch 13, step 500, loss=0.3792772889137268, accuracy=0.8125\n",
      "epoch 13, step 520, loss=0.2510649561882019, accuracy=0.90625\n",
      "epoch 13, step 540, loss=0.32654356956481934, accuracy=0.90625\n",
      "epoch 13, step 560, loss=0.557552695274353, accuracy=0.84375\n",
      "epoch 13, step 580, loss=0.20601701736450195, accuracy=0.90625\n",
      "epoch 13, step 600, loss=0.49740132689476013, accuracy=0.75\n",
      "\n",
      "Epoch    13: reducing learning rate of group 0 to 9.0000e-03.\n",
      "epoch 13, val_loss=0.5670801622464376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158dcd01efbf400f8341bca2c0df6acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 0, loss=0.5227958559989929, accuracy=0.78125\n",
      "epoch 14, step 20, loss=0.44250357151031494, accuracy=0.8125\n",
      "epoch 14, step 40, loss=0.44137880206108093, accuracy=0.8125\n",
      "epoch 14, step 60, loss=0.3505966067314148, accuracy=0.90625\n",
      "epoch 14, step 80, loss=0.28216707706451416, accuracy=0.875\n",
      "epoch 14, step 100, loss=0.3717271089553833, accuracy=0.84375\n",
      "epoch 14, step 120, loss=0.575495719909668, accuracy=0.78125\n",
      "epoch 14, step 140, loss=0.5702390670776367, accuracy=0.8125\n",
      "epoch 14, step 160, loss=0.350790411233902, accuracy=0.90625\n",
      "epoch 14, step 180, loss=0.4424876868724823, accuracy=0.84375\n",
      "epoch 14, step 200, loss=0.40065857768058777, accuracy=0.78125\n",
      "epoch 14, step 220, loss=0.38664937019348145, accuracy=0.8125\n",
      "epoch 14, step 240, loss=0.5138797163963318, accuracy=0.78125\n",
      "epoch 14, step 260, loss=0.6058288216590881, accuracy=0.78125\n",
      "epoch 14, step 280, loss=0.40364667773246765, accuracy=0.90625\n",
      "epoch 14, step 300, loss=0.5628494620323181, accuracy=0.8125\n",
      "epoch 14, step 320, loss=0.3212291896343231, accuracy=0.84375\n",
      "epoch 14, step 340, loss=0.46705761551856995, accuracy=0.875\n",
      "epoch 14, step 360, loss=0.5701820254325867, accuracy=0.75\n",
      "epoch 14, step 380, loss=0.26264920830726624, accuracy=0.90625\n",
      "epoch 14, step 400, loss=0.446536123752594, accuracy=0.84375\n",
      "epoch 14, step 420, loss=0.5824222564697266, accuracy=0.8125\n",
      "epoch 14, step 440, loss=0.22916671633720398, accuracy=0.90625\n",
      "epoch 14, step 460, loss=0.44675910472869873, accuracy=0.875\n",
      "epoch 14, step 480, loss=0.3673721253871918, accuracy=0.875\n",
      "epoch 14, step 500, loss=0.42931199073791504, accuracy=0.875\n",
      "epoch 14, step 520, loss=0.0689840316772461, accuracy=1.0\n",
      "epoch 14, step 540, loss=0.3070529103279114, accuracy=0.90625\n",
      "epoch 14, step 560, loss=0.5250275135040283, accuracy=0.8125\n",
      "epoch 14, step 580, loss=0.1785421222448349, accuracy=0.9375\n",
      "epoch 14, step 600, loss=0.29193612933158875, accuracy=0.9375\n",
      "\n",
      "Epoch    14: reducing learning rate of group 0 to 8.1000e-03.\n",
      "epoch 14, val_loss=0.6312542082194019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782f11c77690442dacb52c6ef4debc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, step 0, loss=0.7606164216995239, accuracy=0.75\n",
      "epoch 15, step 20, loss=0.4262882471084595, accuracy=0.84375\n",
      "epoch 15, step 40, loss=0.731155276298523, accuracy=0.8125\n",
      "epoch 15, step 60, loss=0.16557937860488892, accuracy=0.90625\n",
      "epoch 15, step 80, loss=0.16377417743206024, accuracy=0.9375\n",
      "epoch 15, step 100, loss=0.3474748134613037, accuracy=0.9375\n",
      "epoch 15, step 120, loss=0.45050346851348877, accuracy=0.84375\n",
      "epoch 15, step 140, loss=0.483173131942749, accuracy=0.84375\n",
      "epoch 15, step 160, loss=0.40129369497299194, accuracy=0.8125\n",
      "epoch 15, step 180, loss=0.2126186639070511, accuracy=0.90625\n",
      "epoch 15, step 200, loss=0.3793339133262634, accuracy=0.875\n",
      "epoch 15, step 220, loss=0.365367591381073, accuracy=0.875\n",
      "epoch 15, step 240, loss=0.5208755731582642, accuracy=0.84375\n",
      "epoch 15, step 260, loss=0.5872870683670044, accuracy=0.75\n",
      "epoch 15, step 280, loss=0.44610559940338135, accuracy=0.875\n",
      "epoch 15, step 300, loss=0.27168160676956177, accuracy=0.90625\n",
      "epoch 15, step 320, loss=0.25704309344291687, accuracy=0.90625\n",
      "epoch 15, step 340, loss=0.2834843397140503, accuracy=0.90625\n",
      "epoch 15, step 360, loss=0.6682229042053223, accuracy=0.78125\n",
      "epoch 15, step 380, loss=0.15189586579799652, accuracy=0.9375\n",
      "epoch 15, step 400, loss=0.339146226644516, accuracy=0.90625\n",
      "epoch 15, step 420, loss=0.29349711537361145, accuracy=0.90625\n",
      "epoch 15, step 440, loss=0.14606037735939026, accuracy=0.96875\n",
      "epoch 15, step 460, loss=0.34389597177505493, accuracy=0.875\n",
      "epoch 15, step 480, loss=0.17444860935211182, accuracy=0.9375\n",
      "epoch 15, step 500, loss=0.14165878295898438, accuracy=0.96875\n",
      "epoch 15, step 520, loss=0.05234072357416153, accuracy=1.0\n",
      "epoch 15, step 540, loss=0.36333373188972473, accuracy=0.84375\n",
      "epoch 15, step 560, loss=0.4249042868614197, accuracy=0.8125\n",
      "epoch 15, step 580, loss=0.1757800281047821, accuracy=0.90625\n",
      "epoch 15, step 600, loss=0.5036699175834656, accuracy=0.78125\n",
      "\n",
      "epoch 15, val_loss=0.3068739366443718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e96844f6bf4db681cd0dbc853c2762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, step 0, loss=0.3891902565956116, accuracy=0.875\n",
      "epoch 16, step 20, loss=0.532086968421936, accuracy=0.8125\n",
      "epoch 16, step 40, loss=0.20959125459194183, accuracy=0.90625\n",
      "epoch 16, step 60, loss=0.24494829773902893, accuracy=0.90625\n",
      "epoch 16, step 80, loss=0.17341430485248566, accuracy=0.90625\n",
      "epoch 16, step 100, loss=0.371090292930603, accuracy=0.875\n",
      "epoch 16, step 120, loss=0.3871783912181854, accuracy=0.90625\n",
      "epoch 16, step 140, loss=0.5676125884056091, accuracy=0.84375\n",
      "epoch 16, step 160, loss=0.384351521730423, accuracy=0.875\n",
      "epoch 16, step 180, loss=0.4249950647354126, accuracy=0.84375\n",
      "epoch 16, step 200, loss=0.7180385589599609, accuracy=0.8125\n",
      "epoch 16, step 220, loss=0.33886852860450745, accuracy=0.875\n",
      "epoch 16, step 240, loss=0.531898021697998, accuracy=0.84375\n",
      "epoch 16, step 260, loss=0.4720737636089325, accuracy=0.8125\n",
      "epoch 16, step 280, loss=0.37970882654190063, accuracy=0.875\n",
      "epoch 16, step 300, loss=0.12875989079475403, accuracy=0.96875\n",
      "epoch 16, step 320, loss=0.11037828773260117, accuracy=1.0\n",
      "epoch 16, step 340, loss=0.24065983295440674, accuracy=0.96875\n",
      "epoch 16, step 360, loss=0.3945739269256592, accuracy=0.875\n",
      "epoch 16, step 380, loss=0.3108636736869812, accuracy=0.90625\n",
      "epoch 16, step 400, loss=0.13044561445713043, accuracy=0.90625\n",
      "epoch 16, step 420, loss=0.2549254298210144, accuracy=0.90625\n",
      "epoch 16, step 440, loss=0.22519519925117493, accuracy=0.875\n",
      "epoch 16, step 460, loss=0.2376471608877182, accuracy=0.9375\n",
      "epoch 16, step 480, loss=0.144816055893898, accuracy=0.9375\n",
      "epoch 16, step 500, loss=0.5055965185165405, accuracy=0.90625\n",
      "epoch 16, step 520, loss=0.14304639399051666, accuracy=0.9375\n",
      "epoch 16, step 540, loss=0.13462989032268524, accuracy=0.96875\n",
      "epoch 16, step 560, loss=0.55255126953125, accuracy=0.84375\n",
      "epoch 16, step 580, loss=0.15419791638851166, accuracy=0.9375\n",
      "epoch 16, step 600, loss=0.19932863116264343, accuracy=0.90625\n",
      "\n",
      "Epoch    16: reducing learning rate of group 0 to 7.2900e-03.\n",
      "epoch 16, val_loss=0.4815450331524891\n",
      "Early stopping\n",
      "Finish all training !\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=0, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device=device)\n",
    "\n",
    "# early stopping\n",
    "min_val_loss = np.Inf\n",
    "patience = 3\n",
    "global_step = 1\n",
    "writer = SummaryWriter('runs/experiment_{}'.format(datetime.now().strftime(\"%f\")))\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    val_loss = 0\n",
    "    model_ft.train()\n",
    "    for i, (img_batch, label_batch) in tqdm(enumerate(train_loader)):    \n",
    "        optimizer.zero_grad()      \n",
    "        img_batch = img_batch.to(device=device)\n",
    "        label_batch = label_batch.to(device=device)  \n",
    "        output = model_ft(img_batch)\n",
    "        loss = criterion(output, label_batch.squeeze())\n",
    "        clip_regurization = nn.utils.clip_grad_norm_(model.parameters(), 0.9) \n",
    "#         regularization_loss = 0      \n",
    "#         for param in model.parameters():\n",
    "#             regularization_loss += torch.sum(torch.abs(param))\n",
    "#         loss = loss + 0.1 * regularization_loss\n",
    "        loss = loss + clip_regurization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output.cpu().data, 1)\n",
    "        accuracy = torch.sum(predicted == label_batch.cpu().data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "        \n",
    "        # Write tensorboard\n",
    "        writer.add_scalar('Accuracy/train', accuracy.item(), global_step)\n",
    "        writer.add_scalar('Loss/train', loss.item(), global_step)\n",
    "        writer.add_scalar('LR/train', get_lr(optimizer), global_step)\n",
    "                \n",
    "        global_step += 1\n",
    "#         val_loss += loss.item()\n",
    "        \n",
    "        if i % 20== 0:\n",
    "            print('epoch {}, step {}, loss={}, accuracy={}'.format(epoch+1, i, loss.item(), accuracy.item()))         \n",
    "    \n",
    "#     val_loss = val_loss / len(train_loader)  \n",
    "#     scheduler.step(val_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for i, (img_batch, label_batch) in enumerate(valid_loader):\n",
    "        output = model(img_batch.to(device))\n",
    "        _, predicted = torch.max(output.cpu().data, 1)\n",
    "        loss = criterion(output, label_batch.to(device).squeeze())\n",
    "        accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "        eval_loss += loss.item()\n",
    "        writer.add_scalar('Accuracy/valid', accuracy.item(), global_step)\n",
    "        writer.add_scalar('Loss/valid', loss.item(), global_step)\n",
    "    \n",
    "    eval_loss = eval_loss / len(valid_loader)\n",
    "    scheduler.step(eval_loss)\n",
    "    \n",
    "    print('epoch {}, val_loss={}'.format(epoch+1, eval_loss))         \n",
    "\n",
    "    ## Early Stopping\n",
    "    if eval_loss < min_val_loss:\n",
    "        torch.save(model, 'ckpt/resNet_{}_compose.ckpt'.format(epoch+1))\n",
    "#         save_checkpoint({\n",
    "#             'epoch': epoch+1,\n",
    "#             'state_dict': model.state_dict(),\n",
    "#             'best_loss': val_loss,\n",
    "#             'optimizer' :optimizer.state_dict(),\n",
    "#             }, 'conv_{}.ckpt'.format(epoch+1))\n",
    "        min_val_loss = eval_loss\n",
    "    else:\n",
    "        patience-=1\n",
    "    if patience == 0:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "        \n",
    "writer.close()\n",
    "print('Finish all training !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.875\n",
      "accuracy=0.84375\n",
      "accuracy=0.875\n",
      "accuracy=0.78125\n",
      "accuracy=0.875\n",
      "accuracy=0.8125\n",
      "accuracy=0.875\n",
      "accuracy=0.8125\n",
      "accuracy=0.8125\n",
      "accuracy=0.78125\n",
      "accuracy=0.84375\n",
      "accuracy=0.84375\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.84375\n",
      "accuracy=0.875\n",
      "accuracy=0.90625\n",
      "accuracy=0.90625\n",
      "accuracy=0.9375\n",
      "accuracy=0.90625\n",
      "accuracy=0.875\n",
      "accuracy=0.96875\n",
      "accuracy=0.75\n",
      "accuracy=0.8125\n",
      "accuracy=0.75\n",
      "accuracy=0.8125\n",
      "accuracy=0.84375\n",
      "accuracy=0.90625\n",
      "accuracy=0.96875\n",
      "accuracy=0.90625\n",
      "accuracy=0.84375\n",
      "accuracy=0.9375\n",
      "accuracy=0.84375\n",
      "accuracy=0.78125\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.84375\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.6875\n",
      "accuracy=0.84375\n",
      "accuracy=0.84375\n",
      "accuracy=0.90625\n",
      "accuracy=0.90625\n",
      "accuracy=0.75\n",
      "accuracy=0.84375\n",
      "accuracy=0.96875\n",
      "accuracy=0.96875\n",
      "accuracy=0.9375\n",
      "accuracy=0.9375\n",
      "accuracy=0.84375\n",
      "accuracy=0.96875\n",
      "accuracy=0.84375\n",
      "accuracy=0.9375\n",
      "accuracy=0.84375\n",
      "accuracy=0.8125\n",
      "accuracy=0.9375\n",
      "accuracy=0.90625\n",
      "accuracy=0.875\n",
      "accuracy=0.90625\n",
      "accuracy=0.9375\n",
      "accuracy=0.90625\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for i, (img_batch, label_batch) in enumerate(valid_loader):\n",
    "    output = model(img_batch.to(device))\n",
    "    _, predicted = torch.max(output.cpu().data, 1)\n",
    "    accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "    print('accuracy={}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
