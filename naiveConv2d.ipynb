{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/silence/.pyenv/versions/3.7.2/envs/python-3.7.2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader,SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "LABEL_DIR = 'label2.csv'\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, 'DaanForestPark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHES = 40\n",
    "# FILTER_NUMS = 8\n",
    "# FILTER_NUMS2 = 16\n",
    "CHANNEL_NUMS = 3\n",
    "# KERNEL_SIZE = 13\n",
    "# STRIDE = 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-2\n",
    "VALID_RATIO = .2\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToPILImage() -> Resize() -> ToTensor()\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.3),\n",
    "#         transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])        \n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DataSet and the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None):\n",
    "        _images, _labels = [], []\n",
    "        # total amount of dataset \n",
    "        _number = 0\n",
    "        # Reading the categorical file\n",
    "        label_df = pd.read_csv(label_dir)\n",
    "        \n",
    "        # Iterate all files including .jpg inages  \n",
    "        for subdir, dirs, files in tqdm(os.walk(image_dir)):\n",
    "            for filename in files:\n",
    "                corr_label = label_df[label_df['dirpath']==subdir[len(DATA_DIR)+1:]]['label'].values\n",
    "                if corr_label.size!= 0 and filename.endswith(('jpg')):\n",
    "                    _images.append(subdir + os.sep + filename)\n",
    "                    _labels.append(corr_label)\n",
    "                    _number+=1\n",
    "        \n",
    "        # Randomly arrange data pairs\n",
    "        mapIndexPosition = list(zip(_images, _labels))\n",
    "        random.shuffle(mapIndexPosition)\n",
    "        _images, _labels = zip(*mapIndexPosition)\n",
    "\n",
    "        self._image = iter(_images)\n",
    "        self._labels = iter(_labels)\n",
    "        self._number = _number\n",
    "        self._category = label_df['label'].nunique()\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._number\n",
    "\n",
    "    def __getitem__(self, index):    \n",
    "        img = next(self._image)\n",
    "        lab = next(self._labels)\n",
    "        \n",
    "        img = self._loadimage(img)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)        \n",
    "        return img, lab\n",
    "     \n",
    "    def _categorical(self, label):\n",
    "        return np.arange(self._category) == label[:,None]\n",
    "    \n",
    "    def _loadimage(self, file):\n",
    "        return Image.open(file).convert('RGB')\n",
    "    \n",
    "    def get_categorical_nums(self):\n",
    "        return self._category\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f57c2903fb4c2689296d5858375815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(IMAGE_DIR, LABEL_DIR, transform=transform)\n",
    "\n",
    "valid_size = VALID_RATIO\n",
    "num_train = len(train_dataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=train_sampler, drop_last=True)\n",
    "valid_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, sampler=valid_sampler, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def init_weights(m):\n",
    "#     if type(m) == nn.Conv2d:\n",
    "#         nn.init.xavier_uniform(m.weight)\n",
    "#         m.bias.data.fill_(0.01)\n",
    "#     if type(m) == nn.Linear:\n",
    "#         nn.init.uniform_(m.weight)\n",
    "#         m.bias.data.fill_(0.01)   \n",
    "# class SimpleCNN(nn.Module):\n",
    "    \n",
    "#     def __init__(self, target):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "#         # Input size (3, 1136, 640)\n",
    "# #         self.imgzipper  = nn.AvgPool2d(kernel_size=ZIPSIZE)\n",
    "#         # Input size (3, 284, 160)\n",
    "#         self.conv1 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=CHANNEL_NUMS,\n",
    "#                         out_channels=FILTER_NUMS,\n",
    "#                         kernel_size=KERNEL_SIZE,\n",
    "#                         stride=STRIDE,\n",
    "#                         padding=(KERNEL_SIZE-STRIDE)//2 # padding=(kernel_size-stride)/2 -> original size\n",
    "#                     ),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.ReLU(),\n",
    "#             # (8, 1136, 640)\n",
    "#             nn.MaxPool2d(kernel_size=KERNEL_SIZE)\n",
    "#             # (8, 87, 49)\n",
    "#             # zipper (8, 21, 12)\n",
    "#         ).apply(init_weights)\n",
    "        \n",
    "#         # (8, 87, 49)\n",
    "#         self.conv2 = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=FILTER_NUMS,\n",
    "#                         out_channels=FILTER_NUMS2,\n",
    "#                         kernel_size=KERNEL_SIZE,\n",
    "#                         stride=STRIDE,\n",
    "#                         padding=(KERNEL_SIZE-STRIDE)//2 # padding=(kernel_size-stride)/2 -> original size\n",
    "#                     ),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.ReLU(),\n",
    "#             # (16, 87, 49)\n",
    "#             nn.MaxPool2d(kernel_size=5)\n",
    "#             # (16, 6, 3)\n",
    "#         ).apply(init_weights)\n",
    "#         self.MLP = nn.Sequential(\n",
    "#             nn.Linear(128, 81),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(81, 81),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(81, target)\n",
    "#         ).apply(init_weights)\n",
    "#     def forward(self, x):\n",
    "#         x = self.imgzipper(x)\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.MLP(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SimpleCNN(train_dataset.get_categorical_nums()).to(device)\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, train_dataset.get_categorical_nums())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 分層設定 lr \"\"\"\n",
    "# large_lr_layers = list(map(id,model.fc.parameters()))\n",
    "# small_lr_layers = filter(lambda p:id(p) not in large_lr_layers,model.parameters())\n",
    "# optimizer = torch.optim.SGD([\n",
    "#             {\"params\":large_lr_layers},\n",
    "#             {\"params\":small_lr_layers,\"lr\":1e-4}\n",
    "#             ],lr = 1e-2,momenum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 170, 96]           9,408\n",
      "       BatchNorm2d-2          [-1, 64, 170, 96]             128\n",
      "              ReLU-3          [-1, 64, 170, 96]               0\n",
      "         MaxPool2d-4           [-1, 64, 85, 48]               0\n",
      "            Conv2d-5           [-1, 64, 85, 48]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 85, 48]             128\n",
      "              ReLU-7           [-1, 64, 85, 48]               0\n",
      "            Conv2d-8           [-1, 64, 85, 48]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 85, 48]             128\n",
      "             ReLU-10           [-1, 64, 85, 48]               0\n",
      "       BasicBlock-11           [-1, 64, 85, 48]               0\n",
      "           Conv2d-12           [-1, 64, 85, 48]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 85, 48]             128\n",
      "             ReLU-14           [-1, 64, 85, 48]               0\n",
      "           Conv2d-15           [-1, 64, 85, 48]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 85, 48]             128\n",
      "             ReLU-17           [-1, 64, 85, 48]               0\n",
      "       BasicBlock-18           [-1, 64, 85, 48]               0\n",
      "           Conv2d-19          [-1, 128, 43, 24]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 43, 24]             256\n",
      "             ReLU-21          [-1, 128, 43, 24]               0\n",
      "           Conv2d-22          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 43, 24]             256\n",
      "           Conv2d-24          [-1, 128, 43, 24]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 43, 24]             256\n",
      "             ReLU-26          [-1, 128, 43, 24]               0\n",
      "       BasicBlock-27          [-1, 128, 43, 24]               0\n",
      "           Conv2d-28          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 43, 24]             256\n",
      "             ReLU-30          [-1, 128, 43, 24]               0\n",
      "           Conv2d-31          [-1, 128, 43, 24]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 43, 24]             256\n",
      "             ReLU-33          [-1, 128, 43, 24]               0\n",
      "       BasicBlock-34          [-1, 128, 43, 24]               0\n",
      "           Conv2d-35          [-1, 256, 22, 12]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 22, 12]             512\n",
      "             ReLU-37          [-1, 256, 22, 12]               0\n",
      "           Conv2d-38          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 22, 12]             512\n",
      "           Conv2d-40          [-1, 256, 22, 12]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 22, 12]             512\n",
      "             ReLU-42          [-1, 256, 22, 12]               0\n",
      "       BasicBlock-43          [-1, 256, 22, 12]               0\n",
      "           Conv2d-44          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 22, 12]             512\n",
      "             ReLU-46          [-1, 256, 22, 12]               0\n",
      "           Conv2d-47          [-1, 256, 22, 12]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 22, 12]             512\n",
      "             ReLU-49          [-1, 256, 22, 12]               0\n",
      "       BasicBlock-50          [-1, 256, 22, 12]               0\n",
      "           Conv2d-51           [-1, 512, 11, 6]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-53           [-1, 512, 11, 6]               0\n",
      "           Conv2d-54           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 11, 6]           1,024\n",
      "           Conv2d-56           [-1, 512, 11, 6]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-58           [-1, 512, 11, 6]               0\n",
      "       BasicBlock-59           [-1, 512, 11, 6]               0\n",
      "           Conv2d-60           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-62           [-1, 512, 11, 6]               0\n",
      "           Conv2d-63           [-1, 512, 11, 6]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 11, 6]           1,024\n",
      "             ReLU-65           [-1, 512, 11, 6]               0\n",
      "       BasicBlock-66           [-1, 512, 11, 6]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                   [-1, 85]          43,605\n",
      "================================================================\n",
      "Total params: 11,220,117\n",
      "Trainable params: 11,220,117\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 82.29\n",
      "Params size (MB): 42.80\n",
      "Estimated Total Size (MB): 125.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# channels, H, W\n",
    "model = model_ft.to(device=device)\n",
    "summary(model, input_size=(CHANNEL_NUMS, 340, 192))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning Rate dynamically tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "        \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil \n",
    "def save_checkpoint(model, state, filename='runs/ckpt/model.ckpt'):\n",
    "    torch.save(state, filename)\n",
    "    torch.save(model, 'model_best.ckpt')\n",
    "#     shutil.copyfile(filename, 'model_best.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3520247a08473ab9787d14e776b9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 0,             total_loss=5.353,             accuracy=0.000\n",
      "epoch 1, step 50,             total_loss=6.396,             accuracy=0.000\n",
      "epoch 1, step 100,             total_loss=5.273,             accuracy=0.062\n",
      "epoch 1, step 150,             total_loss=4.536,             accuracy=0.156\n",
      "epoch 1, step 200,             total_loss=4.746,             accuracy=0.062\n",
      "epoch 1, step 250,             total_loss=4.282,             accuracy=0.125\n",
      "epoch 1, step 300,             total_loss=4.505,             accuracy=0.094\n",
      "epoch 1, step 350,             total_loss=4.209,             accuracy=0.125\n",
      "epoch 1, step 400,             total_loss=5.827,             accuracy=0.062\n",
      "epoch 1, step 450,             total_loss=4.463,             accuracy=0.125\n",
      "epoch 1, step 500,             total_loss=4.614,             accuracy=0.156\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 1, val_loss=3.739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae9461d75f241fb8c9182dd24eeed50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, step 0,             total_loss=4.097,             accuracy=0.125\n",
      "epoch 2, step 50,             total_loss=4.061,             accuracy=0.125\n",
      "epoch 2, step 100,             total_loss=4.057,             accuracy=0.188\n",
      "epoch 2, step 150,             total_loss=3.911,             accuracy=0.125\n",
      "epoch 2, step 200,             total_loss=4.178,             accuracy=0.156\n",
      "epoch 2, step 250,             total_loss=3.109,             accuracy=0.250\n",
      "epoch 2, step 300,             total_loss=3.945,             accuracy=0.125\n",
      "epoch 2, step 350,             total_loss=3.530,             accuracy=0.156\n",
      "epoch 2, step 400,             total_loss=4.281,             accuracy=0.219\n",
      "epoch 2, step 450,             total_loss=3.473,             accuracy=0.281\n",
      "epoch 2, step 500,             total_loss=3.630,             accuracy=0.250\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 2, val_loss=2.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b8cf265fbf40828b95448e56a5c886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, step 0,             total_loss=3.203,             accuracy=0.281\n",
      "epoch 3, step 50,             total_loss=3.462,             accuracy=0.156\n",
      "epoch 3, step 100,             total_loss=3.686,             accuracy=0.219\n",
      "epoch 3, step 150,             total_loss=2.847,             accuracy=0.344\n",
      "epoch 3, step 200,             total_loss=2.884,             accuracy=0.438\n",
      "epoch 3, step 250,             total_loss=2.589,             accuracy=0.406\n",
      "epoch 3, step 300,             total_loss=3.098,             accuracy=0.219\n",
      "epoch 3, step 350,             total_loss=3.077,             accuracy=0.281\n",
      "epoch 3, step 400,             total_loss=3.606,             accuracy=0.312\n",
      "epoch 3, step 450,             total_loss=2.767,             accuracy=0.531\n",
      "epoch 3, step 500,             total_loss=3.216,             accuracy=0.281\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 3, val_loss=2.164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005d2450dcad4b87afafba807fc1d50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, step 0,             total_loss=2.962,             accuracy=0.375\n",
      "epoch 4, step 50,             total_loss=2.386,             accuracy=0.469\n",
      "epoch 4, step 100,             total_loss=2.998,             accuracy=0.281\n",
      "epoch 4, step 150,             total_loss=2.178,             accuracy=0.594\n",
      "epoch 4, step 200,             total_loss=2.191,             accuracy=0.562\n",
      "epoch 4, step 250,             total_loss=2.136,             accuracy=0.531\n",
      "epoch 4, step 300,             total_loss=2.686,             accuracy=0.406\n",
      "epoch 4, step 350,             total_loss=2.583,             accuracy=0.344\n",
      "epoch 4, step 400,             total_loss=3.025,             accuracy=0.469\n",
      "epoch 4, step 450,             total_loss=2.763,             accuracy=0.438\n",
      "epoch 4, step 500,             total_loss=2.919,             accuracy=0.375\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 4, val_loss=1.952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e63873a6db4d4aad916fc86b791000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, step 0,             total_loss=2.779,             accuracy=0.438\n",
      "epoch 5, step 50,             total_loss=2.212,             accuracy=0.531\n",
      "epoch 5, step 100,             total_loss=2.674,             accuracy=0.406\n",
      "epoch 5, step 150,             total_loss=1.999,             accuracy=0.656\n",
      "epoch 5, step 200,             total_loss=1.936,             accuracy=0.688\n",
      "epoch 5, step 250,             total_loss=1.716,             accuracy=0.688\n",
      "epoch 5, step 300,             total_loss=2.311,             accuracy=0.500\n",
      "epoch 5, step 350,             total_loss=1.942,             accuracy=0.625\n",
      "epoch 5, step 400,             total_loss=2.592,             accuracy=0.438\n",
      "epoch 5, step 450,             total_loss=2.211,             accuracy=0.500\n",
      "epoch 5, step 500,             total_loss=2.762,             accuracy=0.406\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 5, val_loss=1.627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cd24d08c564a32bf3eb06d6f2eca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, step 0,             total_loss=2.390,             accuracy=0.500\n",
      "epoch 6, step 50,             total_loss=2.016,             accuracy=0.688\n",
      "epoch 6, step 100,             total_loss=2.451,             accuracy=0.375\n",
      "epoch 6, step 150,             total_loss=2.000,             accuracy=0.531\n",
      "epoch 6, step 200,             total_loss=1.918,             accuracy=0.562\n",
      "epoch 6, step 250,             total_loss=1.490,             accuracy=0.812\n",
      "epoch 6, step 300,             total_loss=2.229,             accuracy=0.594\n",
      "epoch 6, step 350,             total_loss=2.140,             accuracy=0.594\n",
      "epoch 6, step 400,             total_loss=2.344,             accuracy=0.438\n",
      "epoch 6, step 450,             total_loss=2.143,             accuracy=0.531\n",
      "epoch 6, step 500,             total_loss=2.430,             accuracy=0.406\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 6, val_loss=1.483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d24a13b6c304f868817f4d1d6e226c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, step 0,             total_loss=2.357,             accuracy=0.469\n",
      "epoch 7, step 50,             total_loss=1.688,             accuracy=0.656\n",
      "epoch 7, step 100,             total_loss=2.491,             accuracy=0.531\n",
      "epoch 7, step 150,             total_loss=2.047,             accuracy=0.531\n",
      "epoch 7, step 200,             total_loss=1.604,             accuracy=0.688\n",
      "epoch 7, step 250,             total_loss=1.606,             accuracy=0.750\n",
      "epoch 7, step 300,             total_loss=2.303,             accuracy=0.438\n",
      "epoch 7, step 350,             total_loss=2.115,             accuracy=0.625\n",
      "epoch 7, step 400,             total_loss=2.273,             accuracy=0.500\n",
      "epoch 7, step 450,             total_loss=1.953,             accuracy=0.625\n",
      "epoch 7, step 500,             total_loss=2.086,             accuracy=0.594\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 7, val_loss=1.290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffbe5e0c1f84019a613ed2b27f2147b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, step 0,             total_loss=2.234,             accuracy=0.625\n",
      "epoch 8, step 50,             total_loss=1.894,             accuracy=0.594\n",
      "epoch 8, step 100,             total_loss=2.111,             accuracy=0.594\n",
      "epoch 8, step 150,             total_loss=1.623,             accuracy=0.750\n",
      "epoch 8, step 200,             total_loss=1.873,             accuracy=0.656\n",
      "epoch 8, step 250,             total_loss=1.462,             accuracy=0.844\n",
      "epoch 8, step 300,             total_loss=1.982,             accuracy=0.594\n",
      "epoch 8, step 350,             total_loss=2.143,             accuracy=0.531\n",
      "epoch 8, step 400,             total_loss=2.232,             accuracy=0.531\n",
      "epoch 8, step 450,             total_loss=1.685,             accuracy=0.656\n",
      "epoch 8, step 500,             total_loss=1.919,             accuracy=0.562\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 8, val_loss=1.180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11499953d46f48c49c9e6a61bdc0d09c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, step 0,             total_loss=2.189,             accuracy=0.594\n",
      "epoch 9, step 50,             total_loss=1.905,             accuracy=0.625\n",
      "epoch 9, step 100,             total_loss=1.760,             accuracy=0.531\n",
      "epoch 9, step 150,             total_loss=1.966,             accuracy=0.594\n",
      "epoch 9, step 200,             total_loss=1.550,             accuracy=0.688\n",
      "epoch 9, step 250,             total_loss=1.371,             accuracy=0.844\n",
      "epoch 9, step 300,             total_loss=1.879,             accuracy=0.625\n",
      "epoch 9, step 350,             total_loss=1.643,             accuracy=0.688\n",
      "epoch 9, step 400,             total_loss=2.173,             accuracy=0.500\n",
      "epoch 9, step 450,             total_loss=1.699,             accuracy=0.625\n",
      "epoch 9, step 500,             total_loss=1.927,             accuracy=0.719\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 9, val_loss=1.173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8972098479a45b4a642af1598c454cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, step 0,             total_loss=1.841,             accuracy=0.625\n",
      "epoch 10, step 50,             total_loss=1.492,             accuracy=0.688\n",
      "epoch 10, step 100,             total_loss=2.261,             accuracy=0.500\n",
      "epoch 10, step 150,             total_loss=1.740,             accuracy=0.750\n",
      "epoch 10, step 200,             total_loss=1.287,             accuracy=0.812\n",
      "epoch 10, step 250,             total_loss=1.535,             accuracy=0.719\n",
      "epoch 10, step 300,             total_loss=2.094,             accuracy=0.531\n",
      "epoch 10, step 350,             total_loss=1.948,             accuracy=0.719\n",
      "epoch 10, step 400,             total_loss=2.212,             accuracy=0.562\n",
      "epoch 10, step 450,             total_loss=1.412,             accuracy=0.812\n",
      "epoch 10, step 500,             total_loss=1.937,             accuracy=0.625\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 10, val_loss=1.098\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3a549f7bbb45bfa9999503b5dd9aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, step 0,             total_loss=1.511,             accuracy=0.688\n",
      "epoch 11, step 50,             total_loss=1.387,             accuracy=0.812\n",
      "epoch 11, step 100,             total_loss=2.054,             accuracy=0.656\n",
      "epoch 11, step 150,             total_loss=1.495,             accuracy=0.812\n",
      "epoch 11, step 200,             total_loss=1.565,             accuracy=0.656\n",
      "epoch 11, step 250,             total_loss=1.239,             accuracy=0.844\n",
      "epoch 11, step 300,             total_loss=1.802,             accuracy=0.656\n",
      "epoch 11, step 350,             total_loss=1.556,             accuracy=0.688\n",
      "epoch 11, step 400,             total_loss=2.251,             accuracy=0.594\n",
      "epoch 11, step 450,             total_loss=1.459,             accuracy=0.781\n",
      "epoch 11, step 500,             total_loss=1.792,             accuracy=0.656\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 11, val_loss=1.011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572197d7ff8646a9a3a095dbe4c4b4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, step 0,             total_loss=1.820,             accuracy=0.594\n",
      "epoch 12, step 50,             total_loss=1.294,             accuracy=0.875\n",
      "epoch 12, step 100,             total_loss=2.104,             accuracy=0.531\n",
      "epoch 12, step 150,             total_loss=1.602,             accuracy=0.625\n",
      "epoch 12, step 200,             total_loss=1.555,             accuracy=0.750\n",
      "epoch 12, step 250,             total_loss=1.620,             accuracy=0.688\n",
      "epoch 12, step 300,             total_loss=1.801,             accuracy=0.719\n",
      "epoch 12, step 350,             total_loss=1.660,             accuracy=0.688\n",
      "epoch 12, step 400,             total_loss=2.322,             accuracy=0.719\n",
      "epoch 12, step 450,             total_loss=1.821,             accuracy=0.625\n",
      "epoch 12, step 500,             total_loss=1.477,             accuracy=0.750\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 12, val_loss=0.863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d076c5d48e74f62b35fba40c680cf58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, step 0,             total_loss=1.535,             accuracy=0.688\n",
      "epoch 13, step 50,             total_loss=1.376,             accuracy=0.781\n",
      "epoch 13, step 100,             total_loss=2.153,             accuracy=0.656\n",
      "epoch 13, step 150,             total_loss=1.372,             accuracy=0.875\n",
      "epoch 13, step 200,             total_loss=1.408,             accuracy=0.812\n",
      "epoch 13, step 250,             total_loss=1.179,             accuracy=0.844\n",
      "epoch 13, step 300,             total_loss=2.202,             accuracy=0.531\n",
      "epoch 13, step 350,             total_loss=1.659,             accuracy=0.688\n",
      "epoch 13, step 400,             total_loss=1.670,             accuracy=0.625\n",
      "epoch 13, step 450,             total_loss=1.271,             accuracy=0.844\n",
      "epoch 13, step 500,             total_loss=1.447,             accuracy=0.812\n",
      "\n",
      "--- Validation phase ---\n",
      "Epoch    13: reducing learning rate of group 0 to 9.0000e-03.\n",
      "epoch 13, val_loss=0.869\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea2c0f6272043eb82344c61ce528ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, step 0,             total_loss=1.728,             accuracy=0.625\n",
      "epoch 14, step 50,             total_loss=1.562,             accuracy=0.719\n",
      "epoch 14, step 100,             total_loss=1.707,             accuracy=0.688\n",
      "epoch 14, step 150,             total_loss=1.639,             accuracy=0.781\n",
      "epoch 14, step 200,             total_loss=1.502,             accuracy=0.750\n",
      "epoch 14, step 250,             total_loss=1.336,             accuracy=0.812\n",
      "epoch 14, step 300,             total_loss=1.722,             accuracy=0.750\n",
      "epoch 14, step 350,             total_loss=1.512,             accuracy=0.781\n",
      "epoch 14, step 400,             total_loss=2.132,             accuracy=0.625\n",
      "epoch 14, step 450,             total_loss=1.285,             accuracy=0.875\n",
      "epoch 14, step 500,             total_loss=1.537,             accuracy=0.812\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 14, val_loss=0.802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8e06faa0bb41ef982fcf961a02eecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, step 0,             total_loss=1.566,             accuracy=0.656\n",
      "epoch 15, step 50,             total_loss=1.197,             accuracy=0.875\n",
      "epoch 15, step 100,             total_loss=1.967,             accuracy=0.719\n",
      "epoch 15, step 150,             total_loss=1.242,             accuracy=0.875\n",
      "epoch 15, step 200,             total_loss=1.530,             accuracy=0.781\n",
      "epoch 15, step 250,             total_loss=1.317,             accuracy=0.781\n",
      "epoch 15, step 300,             total_loss=1.662,             accuracy=0.656\n",
      "epoch 15, step 350,             total_loss=1.775,             accuracy=0.688\n",
      "epoch 15, step 400,             total_loss=1.493,             accuracy=0.656\n",
      "epoch 15, step 450,             total_loss=1.522,             accuracy=0.750\n",
      "epoch 15, step 500,             total_loss=1.288,             accuracy=0.812\n",
      "\n",
      "--- Validation phase ---\n",
      "Epoch    15: reducing learning rate of group 0 to 8.1000e-03.\n",
      "epoch 15, val_loss=0.844\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ea69e9026b4b31bfa7c6ae57969536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, step 0,             total_loss=1.925,             accuracy=0.625\n",
      "epoch 16, step 50,             total_loss=1.356,             accuracy=0.812\n",
      "epoch 16, step 100,             total_loss=1.761,             accuracy=0.750\n",
      "epoch 16, step 150,             total_loss=1.400,             accuracy=0.781\n",
      "epoch 16, step 200,             total_loss=1.309,             accuracy=0.875\n",
      "epoch 16, step 250,             total_loss=1.303,             accuracy=0.781\n",
      "epoch 16, step 300,             total_loss=1.236,             accuracy=0.844\n",
      "epoch 16, step 350,             total_loss=1.424,             accuracy=0.781\n",
      "epoch 16, step 400,             total_loss=2.118,             accuracy=0.688\n",
      "epoch 16, step 450,             total_loss=1.250,             accuracy=0.781\n",
      "epoch 16, step 500,             total_loss=1.267,             accuracy=0.812\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 16, val_loss=0.722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cd9fa028c54de5968d684f10499d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, step 0,             total_loss=1.590,             accuracy=0.719\n",
      "epoch 17, step 50,             total_loss=1.346,             accuracy=0.812\n",
      "epoch 17, step 100,             total_loss=1.609,             accuracy=0.719\n",
      "epoch 17, step 150,             total_loss=1.611,             accuracy=0.781\n",
      "epoch 17, step 200,             total_loss=1.430,             accuracy=0.781\n",
      "epoch 17, step 250,             total_loss=1.061,             accuracy=0.906\n",
      "epoch 17, step 300,             total_loss=1.519,             accuracy=0.719\n",
      "epoch 17, step 350,             total_loss=1.416,             accuracy=0.781\n",
      "epoch 17, step 400,             total_loss=1.706,             accuracy=0.750\n",
      "epoch 17, step 450,             total_loss=1.226,             accuracy=0.781\n",
      "epoch 17, step 500,             total_loss=1.530,             accuracy=0.719\n",
      "\n",
      "--- Validation phase ---\n",
      "epoch 17, val_loss=0.694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a421a7cdff14db58a99823b6efaa8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, step 0,             total_loss=1.362,             accuracy=0.812\n",
      "epoch 18, step 50,             total_loss=1.211,             accuracy=0.844\n",
      "epoch 18, step 100,             total_loss=1.444,             accuracy=0.844\n",
      "epoch 18, step 150,             total_loss=1.739,             accuracy=0.719\n",
      "epoch 18, step 200,             total_loss=1.345,             accuracy=0.812\n",
      "epoch 18, step 250,             total_loss=1.378,             accuracy=0.781\n",
      "epoch 18, step 300,             total_loss=1.593,             accuracy=0.719\n",
      "epoch 18, step 350,             total_loss=1.448,             accuracy=0.812\n",
      "epoch 18, step 400,             total_loss=1.690,             accuracy=0.750\n",
      "epoch 18, step 450,             total_loss=1.117,             accuracy=0.938\n",
      "epoch 18, step 500,             total_loss=1.331,             accuracy=0.812\n",
      "\n",
      "--- Validation phase ---\n",
      "Epoch    18: reducing learning rate of group 0 to 7.2900e-03.\n",
      "epoch 18, val_loss=0.747\n",
      "Early stopping\n",
      "Finish all training !\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=0, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device=device)\n",
    "\n",
    "# early stopping\n",
    "min_val_loss = np.Inf\n",
    "patience = PATIENCE\n",
    "global_step = 1\n",
    "# build the writer file\n",
    "write_file = 'runs/experiment_{}'.format(datetime.now().strftime('%f'))\n",
    "writer = SummaryWriter(write_file)\n",
    "os.mkdir(write_file + '/ckpt')\n",
    "\n",
    "model_ft.train()\n",
    "\n",
    "for epoch in range(EPOCHES):\n",
    "    for i, (img_batch, label_batch) in tqdm(enumerate(train_loader)):    \n",
    "        optimizer.zero_grad()      \n",
    "        img_batch = img_batch.to(device=device)\n",
    "        label_batch = label_batch.to(device=device)  \n",
    "        output = model_ft(img_batch)\n",
    "        loss = criterion(output, label_batch.squeeze())\n",
    "        \n",
    "        # l2 Regularization loss\n",
    "        l1_regularization = 0\n",
    "        l2_regularization = 0\n",
    "        for p in model.parameters():\n",
    "            l1_regularization += torch.norm(p, 1)\n",
    "            l2_regularization += torch.norm(p, 2)\n",
    "        loss = loss + 1e-3 * l2_regularization\n",
    "\n",
    "        loss.backward()\n",
    "        # clip the grandient value for avoiding explosion\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 0.9) \n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(output.cpu().data, 1)\n",
    "        accuracy = torch.sum(predicted == label_batch.cpu().data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "        \n",
    "        # Write tensorboard\n",
    "        writer.add_scalar('train/Accuracy', accuracy.item(), global_step)\n",
    "        writer.add_scalar('train/Loss', loss.item(), global_step)\n",
    "        writer.add_scalar('train/L1RegLoss', l1_regularization.item(), global_step)\n",
    "        writer.add_scalar('train/L2RegLoss', l2_regularization.item(), global_step)\n",
    "        writer.add_scalar('train/LR', get_lr(optimizer), global_step)\n",
    "                \n",
    "        global_step += 1\n",
    "        \n",
    "        if i % 50== 0:\n",
    "            print('epoch {}, step {}, \\\n",
    "            total_loss={:.3f}, \\\n",
    "            accuracy={:.3f}'.format(epoch+1, i, loss.item(), accuracy.item()))\n",
    "    \n",
    "    \n",
    "    print('--- Validation phase ---')\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (img_batch, label_batch) in enumerate(valid_loader):\n",
    "            output = model(img_batch.to(device))\n",
    "            _, predicted = torch.max(output.cpu().data, 1)\n",
    "            loss = criterion(output, label_batch.to(device).squeeze())\n",
    "            accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            # Write tensorboard\n",
    "            for cat in range(train_dataset.get_categorical_nums()):\n",
    "                writer.add_pr_curve('valid/pr_curve', (label_batch == cat).int().squeeze(),\n",
    "                                    (predicted == cat).int().squeeze(), epoch*len(valid_loader)+i)\n",
    "            \n",
    "            writer.add_images('valid/image_batch', img_batch, epoch*len(valid_loader)+i)\n",
    "            writer.add_scalar('valid/Accuracy', accuracy.item(), epoch*len(valid_loader)+i)\n",
    "            writer.add_scalar('valid/Loss', loss.item(), epoch*len(valid_loader)+i)\n",
    "    \n",
    "    eval_loss = eval_loss / len(valid_loader)\n",
    "    \n",
    "    scheduler.step(eval_loss)\n",
    "    \n",
    "    print('epoch {}, val_loss={:.3f}'.format(epoch+1, eval_loss))\n",
    "\n",
    "    ## Early Stopping\n",
    "    if eval_loss < min_val_loss:\n",
    "        save_checkpoint(model, \n",
    "            {\n",
    "            'epoch': epoch+1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_loss': eval_loss,\n",
    "            'optimizer' :optimizer.state_dict(),\n",
    "            }, os.path.join(write_file, 'ckpt/resNet_{}.ckpt'.format(epoch+1)))\n",
    "        min_val_loss = eval_loss\n",
    "    else:\n",
    "        patience-=1\n",
    "    if patience == 0:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "print('Finish all training !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.8102189898490906\n"
     ]
    }
   ],
   "source": [
    "# CKPT_PATH = 'model_best.ckpt'\n",
    "# model.load_state_dict(torch.load(CKPT_PATH)['state_dict'])\n",
    "model.eval()\n",
    "acc = 0\n",
    "for i, (img_batch, label_batch) in enumerate(valid_loader):\n",
    "    output = model(img_batch.to(device))\n",
    "    _, predicted = torch.max(output.cpu().data, 1)\n",
    "    accuracy = torch.sum(predicted == label_batch.data.view(-1), dtype=torch.float32) / BATCH_SIZE\n",
    "    acc += accuracy\n",
    "print('accuracy={}'.format(acc/len(valid_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'whole_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
